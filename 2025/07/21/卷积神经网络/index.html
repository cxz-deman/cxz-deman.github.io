<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
<meta name="viewport"
      content="width=device-width, initial-scale=1.0, maximum-scale=1.0, minimum-scale=1.0">
<meta http-equiv="X-UA-Compatible" content="ie=edge">

    <meta name="author" content="CXZ">





<title>卷积神经网络 | CXZ_note</title>



    <link rel="icon" href="/head.ico">




    <!-- stylesheets list from _config.yml -->
    
    <link rel="stylesheet" href="/css/style.css">
    
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/animate.css/4.1.1/animate.min.css">
    



    <!-- scripts list from _config.yml -->
    
    <script src="/js/script.js"></script>
    
    <script src="/js/tocbot.min.js"></script>
    



    
    
        
    


<meta name="generator" content="Hexo 7.3.0"></head>

<body>
    <script>
        // this function is used to check current theme before page loaded.
        (() => {
            const currentTheme = window.localStorage && window.localStorage.getItem('theme') || '';
            const isDark = currentTheme === 'dark';
            const pagebody = document.getElementsByTagName('body')[0]
            if (isDark) {
                pagebody.classList.add('dark-theme');
                // mobile
                document.getElementById("mobile-toggle-theme").innerText = "· Dark"
            } else {
                pagebody.classList.remove('dark-theme');
                // mobile
                document.getElementById("mobile-toggle-theme").innerText = "· Light"
            }
        })();
    </script>

    <div class="wrapper">
        <header>
    <nav class="navbar">
        <div class="container">
            <div class="navbar-header header-logo"><a href="/">CXZ&#39;s Blog</a></div>
            <div class="menu navbar-right">
                
                    <a class="menu-item" href="/archives">Posts</a>
                
                    <a class="menu-item" href="/category">Categories</a>
                
                    <a class="menu-item" href="/tag">Tags</a>
                
                    <a class="menu-item" href="/about">About</a>
                
                <input id="switch_default" type="checkbox" class="switch_default">
                <label for="switch_default" class="toggleBtn"></label>
            </div>
        </div>
    </nav>

    
    <nav class="navbar-mobile" id="nav-mobile">
        <div class="container">
            <div class="navbar-header">
                <div>
                    <a href="/">CXZ&#39;s Blog</a><a id="mobile-toggle-theme">·&nbsp;Light</a>
                </div>
                <div class="menu-toggle" onclick="mobileBtn()">&#9776; Menu</div>
            </div>
            <div class="menu" id="mobile-menu">
                
                    <a class="menu-item" href="/archives">Posts</a>
                
                    <a class="menu-item" href="/category">Categories</a>
                
                    <a class="menu-item" href="/tag">Tags</a>
                
                    <a class="menu-item" href="/about">About</a>
                
            </div>
        </div>
    </nav>

</header>
<script>
    var mobileBtn = function f() {
        var toggleMenu = document.getElementsByClassName("menu-toggle")[0];
        var mobileMenu = document.getElementById("mobile-menu");
        if(toggleMenu.classList.contains("active")){
           toggleMenu.classList.remove("active")
            mobileMenu.classList.remove("active")
        }else{
            toggleMenu.classList.add("active")
            mobileMenu.classList.add("active")
        }
    }
</script>
            <div class="main">
                <div class="container">
    
    
        <div class="post-toc">
    <div class="tocbot-list">
    </div>
    <div class="tocbot-list-menu">
        <a class="tocbot-toc-expand" onclick="expand_toc()">Expand all</a>
        <a onclick="go_top()">Back to top</a>
        <a onclick="go_bottom()">Go to bottom</a>
    </div>
</div>

<script>
    var tocbot_timer;
    var DEPTH_MAX = 6; // 为 6 时展开所有
    var tocbot_default_config = {
        tocSelector: '.tocbot-list',
        contentSelector: '.post-content',
        headingSelector: 'h1, h2, h3, h4, h5',
        orderedList: false,
        scrollSmooth: true,
        onClick: extend_click,
    };

    function extend_click() {
        clearTimeout(tocbot_timer);
        tocbot_timer = setTimeout(function() {
            tocbot.refresh(obj_merge(tocbot_default_config, {
                hasInnerContainers: true
            }));
        }, 420); // 这个值是由 tocbot 源码里定义的 scrollSmoothDuration 得来的
    }

    document.ready(function() {
        tocbot.init(obj_merge(tocbot_default_config, {
            collapseDepth: 1
        }));
    });

    function expand_toc() {
        var b = document.querySelector('.tocbot-toc-expand');
        var expanded = b.getAttribute('data-expanded');
        expanded ? b.removeAttribute('data-expanded') : b.setAttribute('data-expanded', true);
        tocbot.refresh(obj_merge(tocbot_default_config, {
            collapseDepth: expanded ? 1 : DEPTH_MAX
        }));
        b.innerText = expanded ? 'Expand all' : 'Collapse all';
    }

    function go_top() {
        window.scrollTo(0, 0);
    }

    function go_bottom() {
        window.scrollTo(0, document.body.scrollHeight);
    }

    function obj_merge(target, source) {
        for (var item in source) {
            if (source.hasOwnProperty(item)) {
                target[item] = source[item];
            }
        }
        return target;
    }
</script>
    

    
    <article class="post-wrap">
        <header class="post-header">
            <h1 class="post-title">卷积神经网络</h1>
            
                <div class="post-meta">
                    
                        Author: <a itemprop="author" rel="author" href="/">CXZ</a>
                    

                    
                        <span class="post-time">
                        Date: <a href="#">July 21, 2025&nbsp;&nbsp;16:45:34</a>
                        </span>
                    
                    
                </div>
            
        </header>

        <div class="post-content">
            <h1 id="卷积神经网络"><a href="#卷积神经网络" class="headerlink" title="卷积神经网络"></a>卷积神经网络</h1><h2 id="1入门"><a href="#1入门" class="headerlink" title="1入门"></a>1入门</h2><h3 id="1-1特点"><a href="#1-1特点" class="headerlink" title="1.1特点"></a>1.1特点</h3><ul>
<li><p>卷积-激活-池化</p>
</li>
<li><p>卷积神经网络处理数据的三个特性：局部连接、权值共享、池化</p>
</li>
</ul>
<h4 id="1-1-1-局部连接（Local-Connectivity）"><a href="#1-1-1-局部连接（Local-Connectivity）" class="headerlink" title="1.1.1 局部连接（Local Connectivity）"></a>1.1.1 局部连接（Local Connectivity）</h4><ul>
<li><p><strong>定义</strong><br>每个神经元只与输入数据的<strong>局部区域</strong>相连，而非全连接。<br>例如，在图像处理中，每个神经元仅关注图像的一小块区域（如 5×5 像素），而非整幅图像。</p>
</li>
<li><p><strong>作用</strong>  </p>
<ul>
<li>模拟人类视觉系统的<strong>感受野</strong>机制。  </li>
<li>大幅减少模型参数，降低计算成本。  </li>
<li>帮助网络专注于学习<strong>局部特征</strong>（如边缘、纹理）。</li>
</ul>
</li>
</ul>
<hr>
<h4 id="1-1-2-权重共享（Weight-Sharing）"><a href="#1-1-2-权重共享（Weight-Sharing）" class="headerlink" title="1.1.2. 权重共享（Weight Sharing）"></a>1.1.2. 权重共享（Weight Sharing）</h4><ul>
<li><p><strong>定义</strong><br>同一卷积层中的所有神经元使用<strong>相同的权重向量</strong>（卷积核 &#x2F; 滤波器）来扫描输入数据的不同局部区域；卷积核在滑动过程中<strong>权重保持不变</strong>。</p>
</li>
<li><p><strong>作用</strong>  </p>
<ul>
<li>进一步减少参数数量，提高计算效率。  </li>
<li>赋予模型<strong>平移不变性</strong>（translation invariance）：无论特征出现在图像何处，都能被识别。  </li>
<li>使 CNN 特别适用于图像分类等具有平移不变性的任务。</li>
</ul>
</li>
</ul>
<hr>
<h4 id="1-1-3-池化（Pooling）"><a href="#1-1-3-池化（Pooling）" class="headerlink" title="1.1.3. 池化（Pooling）"></a>1.1.3. 池化（Pooling）</h4><ul>
<li><p><strong>定义</strong><br>通过下采样操作降低特征图的<strong>空间尺寸</strong>，常见形式为 <strong>最大池化（MaxPooling）</strong>：在每个固定大小的子区域内取最大值。</p>
</li>
<li><p><strong>作用</strong>  </p>
<ul>
<li>降低计算复杂度，控制过拟合。  </li>
<li>提供<strong>位置不变性</strong>：对输入中的微小变化不敏感（如物体轻微移动）。  </li>
<li>提取主要特征，去除冗余信息。</li>
</ul>
</li>
</ul>
<p>注意图像文件：</p>
<p>- *.jpg,*.jpeg 有损压缩</p>
<p>- *.png 无损压缩，有透明度，四通道颜色不失真</p>
<h3 id="1-2卷积层"><a href="#1-2卷积层" class="headerlink" title="1.2卷积层"></a>1.2卷积层</h3><h4 id="1-2-1函数"><a href="#1-2-1函数" class="headerlink" title="1.2.1函数"></a>1.2.1函数</h4><p>常用参数</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">nn.Conv2D(in_channels,out_channels,kernel_size,stride,paddng,bias)</span><br></pre></td></tr></table></figure>

<p> in_channels&#x3D;1: 输入通道数</p>
<p> out_channels&#x3D;1: 输出通道数</p>
<p> kernel_size&#x3D;3: 卷积核大小</p>
<p> stride&#x3D;: 卷积核步长</p>
<p> padding&#x3D;0: 填充</p>
<p> bias&#x3D;False): 是否使用偏置</p>
<h4 id="1-2-2示例"><a href="#1-2-2示例" class="headerlink" title="1.2.2示例"></a>1.2.2示例</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"></span><br><span class="line">kernel=torch.tensor([[<span class="number">0</span>,<span class="number">1</span>],[<span class="number">2</span>,<span class="number">3</span>]],dtype=torch.float32)</span><br><span class="line"></span><br><span class="line">input_matrix=torch.tensor([[<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>],[<span class="number">4</span>,<span class="number">5</span>,<span class="number">6</span>],[<span class="number">7</span>,<span class="number">8</span>,<span class="number">9</span>]],dtype=torch.float32)</span><br><span class="line">input_matrix=input_matrix.view(<span class="number">1</span>,<span class="number">1</span>,<span class="number">3</span>,<span class="number">3</span>)<span class="comment">#改变维度的原因：卷积层需要输入的维度为4维</span></span><br><span class="line"></span><br><span class="line">conv_layer=nn.Conv2d(in_channels=<span class="number">1</span>,<span class="comment">#输入通道数</span></span><br><span class="line">                     out_channels=<span class="number">1</span>,<span class="comment">#输出通道数</span></span><br><span class="line">                     kernel_size=<span class="number">3</span>,<span class="comment">#卷积核大小</span></span><br><span class="line">                     stride=<span class="number">1</span>,<span class="comment">#卷积核步长</span></span><br><span class="line">                     padding=<span class="number">0</span>,<span class="comment">#填充</span></span><br><span class="line">                     bias=<span class="literal">False</span>)<span class="comment">#是否使用偏置</span></span><br><span class="line">conv_layer.weight.data=kernel.view(<span class="number">1</span>,<span class="number">1</span>,<span class="number">2</span>,<span class="number">2</span>)<span class="comment">#改变维度的原因：卷积层需要输入的维度为4维</span></span><br><span class="line"></span><br><span class="line">output=conv_layer(input_matrix)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(output)</span><br></pre></td></tr></table></figure>

<hr>
<h3 id="1-3池化层"><a href="#1-3池化层" class="headerlink" title="1.3池化层"></a>1.3池化层</h3><h4 id="1-3-1最大池化"><a href="#1-3-1最大池化" class="headerlink" title="1.3.1最大池化"></a>1.3.1最大池化</h4><p>在卷积核内最大值作为特征</p>
<h4 id="1-3-2均值池化"><a href="#1-3-2均值池化" class="headerlink" title="1.3.2均值池化"></a>1.3.2均值池化</h4><p>在卷积核内所有数求均值作为特征</p>
<h4 id="1-3-3函数"><a href="#1-3-3函数" class="headerlink" title="1.3.3函数"></a>1.3.3函数</h4><p>kerel_size核的大小，stride步长</p>
<h5 id="1-3-3-1最大池化函数"><a href="#1-3-3-1最大池化函数" class="headerlink" title="1.3.3.1最大池化函数"></a>1.3.3.1最大池化函数</h5><p>max_pool_layer&#x3D;nn.MaxPool2d(kernel_size&#x3D;2, stride&#x3D;3)</p>
<h5 id="1-3-3-2均值池化函数"><a href="#1-3-3-2均值池化函数" class="headerlink" title="1.3.3.2均值池化函数"></a>1.3.3.2均值池化函数</h5><p>ave_pool_layer&#x3D;nn.AvgPool2d(kernel_size&#x3D;2, stride&#x3D;3)</p>
<h4 id="1-3-4示例"><a href="#1-3-4示例" class="headerlink" title="1.3.4示例"></a>1.3.4示例</h4><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#池化操作代码</span></span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义输入张量</span></span><br><span class="line">input_tensor = torch.randn(<span class="number">1</span>, <span class="number">1</span>, <span class="number">5</span>, <span class="number">5</span>)  <span class="comment"># 形状为 [batch_size, channels, height, width]</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建一个 NumPy 数组</span></span><br><span class="line">matrix_np = np.array([[[[<span class="number">1.0</span>, <span class="number">0.0</span>, <span class="number">0.0</span>, <span class="number">0.0</span>, <span class="number">1.0</span>],</span><br><span class="line">                        [<span class="number">0.0</span>, <span class="number">1.0</span>, <span class="number">0.0</span>, <span class="number">1.0</span>, <span class="number">0.0</span>],</span><br><span class="line">                        [<span class="number">0.0</span>, <span class="number">0.0</span>, <span class="number">1.0</span>, <span class="number">0.0</span>, <span class="number">0.0</span>],</span><br><span class="line">                        [<span class="number">0.0</span>, <span class="number">1.0</span>, <span class="number">0.0</span>, <span class="number">1.0</span>, <span class="number">0.0</span>],</span><br><span class="line">                        [<span class="number">1.0</span>, <span class="number">0.0</span>, <span class="number">0.0</span>, <span class="number">0.0</span>, <span class="number">1.0</span>]]]],dtype=np.float32)</span><br><span class="line">kernel = torch.tensor([</span><br><span class="line">    [<span class="number">0.</span>, <span class="number">0.</span>, <span class="number">1.</span>],</span><br><span class="line">    [<span class="number">0.</span>, <span class="number">1.</span>, <span class="number">0.</span>],</span><br><span class="line">    [<span class="number">1.</span>, <span class="number">0.</span>, <span class="number">0.</span>]</span><br><span class="line">], dtype=torch.float32)</span><br><span class="line"></span><br><span class="line">matrix_np=torch.from_numpy(matrix_np)</span><br><span class="line"></span><br><span class="line">conv_layer = nn.Conv2d(<span class="number">1</span>, <span class="number">1</span>, kernel_size=<span class="number">3</span>, stride=<span class="number">1</span>, padding=<span class="number">1</span>)</span><br><span class="line">conv_layer.weight.data = kernel.view(<span class="number">1</span>, <span class="number">1</span>, <span class="number">3</span>, <span class="number">3</span>)</span><br><span class="line"></span><br><span class="line">output_np = conv_layer(matrix_np)</span><br><span class="line"><span class="built_in">print</span>(output_np)</span><br><span class="line"></span><br><span class="line">max_pool_layer=nn.MaxPool2d(kernel_size=<span class="number">2</span>, stride=<span class="number">3</span>)</span><br><span class="line">ave_pool_layer=nn.AvgPool2d(kernel_size=<span class="number">2</span>, stride=<span class="number">3</span>)</span><br><span class="line">max_out=max_pool_layer(output_np)</span><br><span class="line">ave_out=ave_pool_layer(output_np)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Max Pool Output:&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(torch.<span class="built_in">round</span>(max_out))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Average Pool Output:&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(torch.<span class="built_in">round</span>(ave_out))</span><br></pre></td></tr></table></figure>

<p>输出：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">tensor([[[[ 0.7703, -0.2297,  0.7703, -0.2297,  1.7703],</span><br><span class="line">          [-0.2297,  0.7703, -0.2297,  2.7703, -0.2297],</span><br><span class="line">          [ 0.7703, -0.2297,  2.7703, -0.2297,  0.7703],</span><br><span class="line">          [-0.2297,  2.7703, -0.2297,  0.7703, -0.2297],</span><br><span class="line">          [ 1.7703, -0.2297,  0.7703, -0.2297,  0.7703]]]],</span><br><span class="line">       grad_fn=&lt;ConvolutionBackward0&gt;)</span><br><span class="line">Max Pool Output:</span><br><span class="line">tensor([[[[1., 3.],</span><br><span class="line">          [3., 1.]]]], grad_fn=&lt;RoundBackward0&gt;)</span><br><span class="line">Average Pool Output:</span><br><span class="line">tensor([[[[0., 1.],</span><br><span class="line">          [1., 0.]]]], grad_fn=&lt;RoundBackward0&gt;)</span><br></pre></td></tr></table></figure>

<h3 id="1-4搭建神经网络实战"><a href="#1-4搭建神经网络实战" class="headerlink" title="1.4搭建神经网络实战"></a>1.4搭建神经网络实战</h3><h4 id="1-4-1搭建方法"><a href="#1-4-1搭建方法" class="headerlink" title="1.4.1搭建方法"></a>1.4.1搭建方法</h4><h5 id="1-4-1-1直接搭建"><a href="#1-4-1-1直接搭建" class="headerlink" title="1.4.1.1直接搭建"></a>1.4.1.1直接搭建</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">SimpleCNN</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>(SimpleCNN,<span class="variable language_">self</span>).__init__()</span><br><span class="line">        <span class="variable language_">self</span>.conv1 = nn.Conv2d(<span class="number">3</span>,<span class="number">8</span>,<span class="number">5</span>,<span class="number">1</span>,<span class="number">1</span>)</span><br><span class="line">        <span class="variable language_">self</span>.relu1= nn.ReLU()</span><br><span class="line">        <span class="variable language_">self</span>.pool = nn.MaxPool2d(<span class="number">2</span>,<span class="number">2</span>)</span><br><span class="line">        <span class="variable language_">self</span>.conv2 = nn.Conv2d(<span class="number">8</span>,<span class="number">16</span>,<span class="number">5</span>,<span class="number">1</span>,<span class="number">1</span>)</span><br><span class="line">        <span class="variable language_">self</span>.relu2= nn.ReLU()</span><br><span class="line">        <span class="variable language_">self</span>.pool2= nn.MaxPool2d(<span class="number">2</span>,<span class="number">2</span>)</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self,x</span>):</span><br><span class="line">        x = <span class="variable language_">self</span>.pool(<span class="variable language_">self</span>.relu1(<span class="variable language_">self</span>.conv1(x)))</span><br><span class="line">        x = <span class="variable language_">self</span>.pool2(<span class="variable language_">self</span>.relu2(<span class="variable language_">self</span>.conv2(x)))</span><br><span class="line">        <span class="keyword">return</span> x</span><br></pre></td></tr></table></figure>

<p>输出：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">——————输出模型结构——————</span><br><span class="line">SimpleCNN(</span><br><span class="line">  (conv1): Conv2d(3, 8, kernel_size=(5, 5), stride=(1, 1), padding=(1, 1))</span><br><span class="line">  (relu1): ReLU()</span><br><span class="line">  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)</span><br><span class="line">  (conv2): Conv2d(8, 16, kernel_size=(5, 5), stride=(1, 1), padding=(1, 1))</span><br><span class="line">  (relu2): ReLU()</span><br><span class="line">  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)</span><br><span class="line">)</span><br></pre></td></tr></table></figure>



<h5 id="1-4-1-2使用nn-Sequential搭建"><a href="#1-4-1-2使用nn-Sequential搭建" class="headerlink" title="1.4.1.2使用nn.Sequential搭建"></a>1.4.1.2使用nn.Sequential搭建</h5><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">SimpleCNN</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>(SimpleCNN,<span class="variable language_">self</span>).__init__()<span class="comment">#后面可以拼一个全连接层</span></span><br><span class="line">        <span class="variable language_">self</span>.features=nn.Sequential(</span><br><span class="line">            nn.Conv2d(<span class="number">3</span>,<span class="number">8</span>,<span class="number">5</span>,<span class="number">1</span>,<span class="number">1</span>),</span><br><span class="line">            nn.ReLU(),</span><br><span class="line">            nn.MaxPool2d(<span class="number">2</span>,<span class="number">2</span>),</span><br><span class="line">            nn.Conv2d(<span class="number">8</span>,<span class="number">16</span>,<span class="number">5</span>,<span class="number">1</span>,<span class="number">1</span>),</span><br><span class="line">            nn.ReLU(),</span><br><span class="line">            nn.MaxPool2d(<span class="number">2</span>,<span class="number">2</span>),</span><br><span class="line">            nn.Linear(<span class="number">16</span>*<span class="number">5</span>*<span class="number">5</span>,<span class="number">10</span>)</span><br><span class="line">        )</span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    model = SimpleCNN()</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;——————输出模型结构——————&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(model)</span><br><span class="line">    <span class="built_in">print</span>(model.features[<span class="number">3</span>])</span><br></pre></td></tr></table></figure>

<p>输出：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">——————输出模型结构——————</span><br><span class="line">SimpleCNN(</span><br><span class="line">  (features): Sequential(</span><br><span class="line">    (0): Conv2d(3, 8, kernel_size=(5, 5), stride=(1, 1), padding=(1, 1))</span><br><span class="line">    (1): ReLU()</span><br><span class="line">    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)</span><br><span class="line">    (3): Conv2d(8, 16, kernel_size=(5, 5), stride=(1, 1), padding=(1, 1))</span><br><span class="line">    (4): ReLU()</span><br><span class="line">    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)</span><br><span class="line">    (6): Linear(in_features=400, out_features=10, bias=True)</span><br><span class="line">  )</span><br><span class="line">)</span><br><span class="line">Conv2d(8, 16, kernel_size=(5, 5), stride=(1, 1), padding=(1, 1))</span><br></pre></td></tr></table></figure>

<p>可以使用model.features[3]提取的单个一层神经元</p>
<h5 id="1-4-1-3注意"><a href="#1-4-1-3注意" class="headerlink" title="1.4.1.3注意"></a>1.4.1.3<strong>注意</strong></h5><p>除了按顺序执行，nn.Sequential不提供其他功能。</p>
<p>如果你的网络结构有分支、跳跃连接(如ResNet中的shortcut)、多个输入输出等复杂结构，就不适合用nn.Sequential，而应</p>
<p>该自定义forward方法。 </p>
<h4 id="1-4-2项目实战"><a href="#1-4-2项目实战" class="headerlink" title="1.4.2项目实战"></a>1.4.2项目实战</h4><h5 id="1-4-2-1检测图像边缘"><a href="#1-4-2-1检测图像边缘" class="headerlink" title="1.4.2.1检测图像边缘"></a>1.4.2.1检测图像边缘</h5><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"><span class="keyword">import</span> torchvision.transforms <span class="keyword">as</span> transforms</span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义简单的CNN模型</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">EdgeDetectionCNN</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>(EdgeDetectionCNN, <span class="variable language_">self</span>).__init__()</span><br><span class="line">        <span class="comment"># 使用固定的边缘检测卷积核</span></span><br><span class="line">        <span class="variable language_">self</span>.conv1 = nn.Conv2d(<span class="number">1</span>, <span class="number">2</span>, kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>, bias=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 手动设置卷积核权重（水平和垂直边缘检测）</span></span><br><span class="line">        sobel_x = torch.tensor([[[[-<span class="number">1</span>, <span class="number">0</span>, <span class="number">1</span>],</span><br><span class="line">                                  [-<span class="number">2</span>, <span class="number">0</span>, <span class="number">2</span>],</span><br><span class="line">                                  [-<span class="number">1</span>, <span class="number">0</span>, <span class="number">1</span>]]]], dtype=torch.float32)</span><br><span class="line"></span><br><span class="line">        sobel_y = torch.tensor([[[[-<span class="number">1</span>, -<span class="number">2</span>, -<span class="number">1</span>],</span><br><span class="line">                                  [<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>],</span><br><span class="line">                                  [<span class="number">1</span>, <span class="number">2</span>, <span class="number">1</span>]]]], dtype=torch.float32)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 组合两个卷积核</span></span><br><span class="line">        edge_kernels = torch.cat([sobel_x, sobel_y], dim=<span class="number">0</span>)<span class="comment">#dim=0表示横向拼接,dim=1表示纵向拼接</span></span><br><span class="line">        <span class="variable language_">self</span>.conv1.weight = nn.Parameter(edge_kernels, requires_grad=<span class="literal">False</span>)<span class="comment">#作用：禁止参数的梯度计算</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        <span class="comment"># 应用边缘检测卷积</span></span><br><span class="line">        edge_features = <span class="variable language_">self</span>.conv1(x)</span><br><span class="line">        <span class="comment"># 分离水平和垂直特征</span></span><br><span class="line">        horizontal = edge_features[:, <span class="number">0</span>:<span class="number">1</span>, :, :]</span><br><span class="line">        vertical = edge_features[:, <span class="number">1</span>:<span class="number">2</span>, :, :]</span><br><span class="line">        <span class="comment"># 计算边缘强度</span></span><br><span class="line">        edge_magnitude = torch.sqrt(horizontal ** <span class="number">2</span> + vertical ** <span class="number">2</span>)</span><br><span class="line">        <span class="keyword">return</span> edge_magnitude, horizontal, vertical</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 图像预处理</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">preprocess_image</span>(<span class="params">image_path</span>):</span><br><span class="line">    <span class="comment"># 打开图像并转换为灰度</span></span><br><span class="line">    image = Image.<span class="built_in">open</span>(image_path).convert(<span class="string">&#x27;L&#x27;</span>)</span><br><span class="line">    transform = transforms.Compose([</span><br><span class="line">        transforms.ToTensor(),</span><br><span class="line">        transforms.Normalize(mean=[<span class="number">0.5</span>], std=[<span class="number">0.5</span>])</span><br><span class="line">    ])</span><br><span class="line">    <span class="comment"># 添加batch维度 [1, 1, H, W]</span></span><br><span class="line">    image_tensor = transform(image).unsqueeze(<span class="number">0</span>)</span><br><span class="line">    <span class="keyword">return</span> image_tensor, image</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 可视化结果</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">visualize_results</span>(<span class="params">original, horizontal, vertical, magnitude</span>):</span><br><span class="line">    plt.figure(figsize=(<span class="number">12</span>, <span class="number">10</span>))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 原始图像</span></span><br><span class="line">    plt.subplot(<span class="number">2</span>, <span class="number">2</span>, <span class="number">1</span>)</span><br><span class="line">    plt.imshow(original, cmap=<span class="string">&#x27;gray&#x27;</span>)</span><br><span class="line">    plt.title(<span class="string">&#x27;Original Image&#x27;</span>)</span><br><span class="line">    plt.axis(<span class="string">&#x27;off&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 水平边缘</span></span><br><span class="line">    plt.subplot(<span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>)</span><br><span class="line">    plt.imshow(horizontal, cmap=<span class="string">&#x27;gray&#x27;</span>)</span><br><span class="line">    plt.title(<span class="string">&#x27;Horizontal Edges&#x27;</span>)</span><br><span class="line">    plt.axis(<span class="string">&#x27;off&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 垂直边缘</span></span><br><span class="line">    plt.subplot(<span class="number">2</span>, <span class="number">2</span>, <span class="number">3</span>)</span><br><span class="line">    plt.imshow(vertical, cmap=<span class="string">&#x27;gray&#x27;</span>)</span><br><span class="line">    plt.title(<span class="string">&#x27;Vertical Edges&#x27;</span>)</span><br><span class="line">    plt.axis(<span class="string">&#x27;off&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 边缘强度</span></span><br><span class="line">    plt.subplot(<span class="number">2</span>, <span class="number">2</span>, <span class="number">4</span>)</span><br><span class="line">    plt.imshow(magnitude, cmap=<span class="string">&#x27;gray&#x27;</span>)</span><br><span class="line">    plt.title(<span class="string">&#x27;Edge Magnitude&#x27;</span>)</span><br><span class="line">    plt.axis(<span class="string">&#x27;off&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    plt.tight_layout()</span><br><span class="line">    plt.savefig(<span class="string">&#x27;edge_detection_result.png&#x27;</span>)</span><br><span class="line">    plt.show()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 主流程</span></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    <span class="comment"># 1. 初始化模型</span></span><br><span class="line">    model = EdgeDetectionCNN()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 2. 加载和预处理图像</span></span><br><span class="line">    image_tensor, original_image = preprocess_image(<span class="string">&#x27;../images/pig.png&#x27;</span>)  <span class="comment"># 替换为你的图片路径</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 3. 提取边缘特征</span></span><br><span class="line">    <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">        edge_magnitude, horizontal, vertical = model(image_tensor)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 4. 转换为numpy并后处理</span></span><br><span class="line">    horizontal_np = horizontal.squeeze().numpy()</span><br><span class="line">    vertical_np = vertical.squeeze().numpy()</span><br><span class="line">    magnitude_np = edge_magnitude.squeeze().numpy()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 5. 可视化结果</span></span><br><span class="line">    visualize_results(original_image,</span><br><span class="line">                      horizontal_np,</span><br><span class="line">                      vertical_np,</span><br><span class="line">                      magnitude_np)</span><br></pre></td></tr></table></figure>

<h5 id="1-4-2-2利用LeNet训练MINST数据集"><a href="#1-4-2-2利用LeNet训练MINST数据集" class="headerlink" title="1.4.2.2利用LeNet训练MINST数据集"></a>1.4.2.2利用LeNet训练MINST数据集</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"><span class="keyword">import</span> torch.optim <span class="keyword">as</span> optim</span><br><span class="line"><span class="keyword">from</span> torchvision <span class="keyword">import</span> datasets, transforms</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">from</span> matplotlib <span class="keyword">import</span> pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"><span class="keyword">class</span> <span class="title class_">LeNet</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>(LeNet, <span class="variable language_">self</span>).__init__()</span><br><span class="line">        <span class="variable language_">self</span>.conv1 = nn.Conv2d(<span class="number">1</span>, <span class="number">6</span>, <span class="number">5</span>)</span><br><span class="line">        <span class="variable language_">self</span>.relu = nn.ReLU()</span><br><span class="line">        <span class="variable language_">self</span>.maxpool1 = nn.MaxPool2d(<span class="number">2</span>, <span class="number">2</span>)</span><br><span class="line">        <span class="variable language_">self</span>.conv2 = nn.Conv2d(<span class="number">6</span>, <span class="number">16</span>, <span class="number">5</span>)</span><br><span class="line">        <span class="variable language_">self</span>.maxpool2 = nn.MaxPool2d(<span class="number">2</span>, <span class="number">2</span>)</span><br><span class="line">        <span class="variable language_">self</span>.fc1 = nn.Linear(<span class="number">16</span> * <span class="number">5</span> * <span class="number">5</span>, <span class="number">120</span>)</span><br><span class="line">        <span class="variable language_">self</span>.fc2 = nn.Linear(<span class="number">120</span>, <span class="number">84</span>)</span><br><span class="line">        <span class="variable language_">self</span>.fc3 = nn.Linear(<span class="number">84</span>, <span class="number">10</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        x = <span class="variable language_">self</span>.conv1(x)</span><br><span class="line">        x = <span class="variable language_">self</span>.relu(x)</span><br><span class="line">        x = <span class="variable language_">self</span>.maxpool1(x)</span><br><span class="line">        x = <span class="variable language_">self</span>.conv2(x)</span><br><span class="line">        x = <span class="variable language_">self</span>.maxpool2(x)</span><br><span class="line">        x = x.view(-<span class="number">1</span>, <span class="number">16</span> * <span class="number">5</span> * <span class="number">5</span>)</span><br><span class="line">        x = F.relu(<span class="variable language_">self</span>.fc1(x))</span><br><span class="line">        x = F.relu(<span class="variable language_">self</span>.fc2(x))</span><br><span class="line">        x = <span class="variable language_">self</span>.fc3(x)</span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"><span class="keyword">def</span> <span class="title function_">train</span>(<span class="params">model,train_loader,opt,criterion,epochs</span>):</span><br><span class="line">    model.train()</span><br><span class="line">    device = torch.device(<span class="string">&#x27;cuda&#x27;</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">&#x27;cpu&#x27;</span>)</span><br><span class="line">    model.to(device)</span><br><span class="line">    batch=<span class="number">0</span></span><br><span class="line">    acc_list = []</span><br><span class="line">    loss_list=[]</span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(epochs):</span><br><span class="line">        <span class="keyword">for</span> data,target <span class="keyword">in</span> train_loader:</span><br><span class="line">            data,target = data.to(device),target.to(device)</span><br><span class="line">            pre=model(data)</span><br><span class="line">            loss = criterion(pre,target)</span><br><span class="line">            <span class="comment">#精确度</span></span><br><span class="line">            acc = (pre.argmax(dim=<span class="number">1</span>)==target).<span class="built_in">float</span>().mean()</span><br><span class="line">            opt.zero_grad()</span><br><span class="line">            loss.backward()</span><br><span class="line">            opt.step()</span><br><span class="line">            batch += <span class="number">1</span></span><br><span class="line">            acc_list.append(acc.item())</span><br><span class="line">            loss_list.append(loss.item())</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&#x27;Epoch:&#x27;</span>,epoch,<span class="string">&#x27;batch:&#x27;</span>,batch,<span class="string">&#x27;Loss:&#x27;</span>,loss.item(),<span class="string">&#x27;Acc:&#x27;</span>,acc.item())</span><br><span class="line">    <span class="keyword">return</span> model,acc_list,loss_list</span><br><span class="line"><span class="keyword">def</span> <span class="title function_">eval</span>(<span class="params">model,test_loader</span>):</span><br><span class="line">    model.<span class="built_in">eval</span>()</span><br><span class="line">    device = torch.device(<span class="string">&#x27;cuda&#x27;</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">&#x27;cpu&#x27;</span>)</span><br><span class="line">    model.to(device)</span><br><span class="line">    correct = <span class="number">0</span></span><br><span class="line">    <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">        <span class="keyword">for</span> data,target <span class="keyword">in</span> test_loader:</span><br><span class="line">            data,target = data.to(device),target.to(device)</span><br><span class="line">            pre = model(data)</span><br><span class="line">            pred = pre.argmax(dim=<span class="number">1</span>,keepdim=<span class="literal">True</span>)</span><br><span class="line">            correct += pred.eq(target.view_as(pred)).<span class="built_in">sum</span>().item()</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;Accuracy:&#x27;</span>,correct/<span class="built_in">len</span>(test_loader.dataset))</span><br><span class="line">    </span><br><span class="line"><span class="keyword">def</span> <span class="title function_">test_img</span>(<span class="params">model,img_path,transform</span>):</span><br><span class="line">    img=Image.<span class="built_in">open</span>(img_path).convert(<span class="string">&#x27;L&#x27;</span>)</span><br><span class="line">    img = transform(img)</span><br><span class="line">    img = img.unsqueeze(<span class="number">0</span>).to(<span class="string">&#x27;cuda&#x27;</span>)</span><br><span class="line">    device = torch.device(<span class="string">&#x27;cuda&#x27;</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">&#x27;cpu&#x27;</span>)</span><br><span class="line">    model.to(device)</span><br><span class="line">    pre=model(img)</span><br><span class="line">    pred=pre.argmax(dim=<span class="number">1</span>,keepdim=<span class="literal">True</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;Prediction:&#x27;</span>,pred.item())</span><br><span class="line">    </span><br><span class="line"><span class="keyword">def</span> <span class="title function_">model_save</span>(<span class="params">model, model_path</span>):</span><br><span class="line">    torch.save(model.state_dict(), model_path)</span><br><span class="line"><span class="keyword">def</span> <span class="title function_">model_load</span>(<span class="params">model_class, model_path</span>):</span><br><span class="line">    model = model_class()  <span class="comment"># 重新构建模型结构</span></span><br><span class="line">    model.load_state_dict(torch.load(model_path, weights_only=<span class="literal">True</span>))</span><br><span class="line">    model.<span class="built_in">eval</span>()</span><br><span class="line">    <span class="keyword">return</span> model</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    transform=transforms.Compose([</span><br><span class="line">        <span class="comment"># 随机旋转图片</span></span><br><span class="line">        <span class="comment"># MNIST 是手写数字数据集，左右翻转可能造成语义错误（例如，6 和 9 会被混淆）。所以不建议使用</span></span><br><span class="line">        <span class="comment"># transforms.RandomHorizontalFlip(),</span></span><br><span class="line">        <span class="comment"># 将图片尺寸resize到32x32</span></span><br><span class="line">        transforms.Resize((<span class="number">32</span>, <span class="number">32</span>)),</span><br><span class="line">        <span class="comment"># 将图片转化为Tensor格式</span></span><br><span class="line">        transforms.ToTensor(),</span><br><span class="line">        <span class="comment"># 正则化(当模型出现过拟合的情况时，用来降低模型的复杂度)</span></span><br><span class="line">        transforms.Normalize((<span class="number">0.1307</span>,), (<span class="number">0.3081</span>,))</span><br><span class="line">    ])</span><br><span class="line">    <span class="comment"># 加载 MNIST 训练集和测试集</span></span><br><span class="line">    train_dataset = datasets.MNIST(</span><br><span class="line">        root=<span class="string">&#x27;./code&#x27;</span>,</span><br><span class="line">        train=<span class="literal">True</span>,</span><br><span class="line">        transform=transform,</span><br><span class="line">        download=<span class="literal">False</span></span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    test_dataset = datasets.MNIST(</span><br><span class="line">        root=<span class="string">&#x27;./code&#x27;</span>,</span><br><span class="line">        train=<span class="literal">False</span>,</span><br><span class="line">        transform=transform,</span><br><span class="line">        download=<span class="literal">False</span></span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 使用 DataLoader 批量加载</span></span><br><span class="line">    train_loader = DataLoader(</span><br><span class="line">        dataset=train_dataset,</span><br><span class="line">        batch_size=<span class="number">64</span>,</span><br><span class="line">        shuffle=<span class="literal">True</span></span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    test_loader = DataLoader(</span><br><span class="line">        dataset=test_dataset,</span><br><span class="line">        batch_size=<span class="number">64</span>,</span><br><span class="line">        shuffle=<span class="literal">False</span></span><br><span class="line">    )</span><br><span class="line">    model = LeNet()</span><br><span class="line">    opt=optim.Adam(model.parameters(),lr=<span class="number">0.001</span>)</span><br><span class="line">    criterion = nn.CrossEntropyLoss()</span><br><span class="line">    epochs = <span class="number">10</span></span><br><span class="line">    new_model,acc_list,loss_list = train(model,train_loader,opt,criterion,epochs)</span><br><span class="line">    <span class="built_in">eval</span>(new_model,test_loader)</span><br><span class="line">    test_img(new_model,<span class="string">&#x27;./images/3.png&#x27;</span>,transform)</span><br><span class="line">    model_save(new_model,<span class="string">&#x27;./model/model_Mnist.pt&#x27;</span>)</span><br><span class="line">    </span><br><span class="line">    fig,ax = plt.subplots(<span class="number">1</span>,<span class="number">2</span>)</span><br><span class="line">    ax[<span class="number">0</span>].plot(acc_list)</span><br><span class="line">    ax[<span class="number">0</span>].set_title(<span class="string">&#x27;acc&#x27;</span>)</span><br><span class="line">    </span><br><span class="line">    ax[<span class="number">1</span>].plot(loss_list)</span><br><span class="line">    ax[<span class="number">1</span>].set_title(<span class="string">&#x27;loss&#x27;</span>)</span><br><span class="line">    plt.show()</span><br><span class="line">    </span><br></pre></td></tr></table></figure>

<h3 id="1-5模型评估"><a href="#1-5模型评估" class="headerlink" title="1.5模型评估"></a>1.5模型评估</h3><h4 id="1-5-1准确率"><a href="#1-5-1准确率" class="headerlink" title="1.5.1准确率"></a>1.5.1准确率</h4><p>$\text{Accuracy} &#x3D; \frac{\text{TP} + \text{TN}}{\text{TP} + \text{TN} + \text{FP} + \text{FN}}$</p>
<p>判断模型对于任意数据，正确判断的概率</p>
<p><strong>案例：</strong></p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#准确率</span></span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> confusion_matrix,accuracy_score</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> seaborn <span class="keyword">as</span> sns</span><br><span class="line"></span><br><span class="line"><span class="comment"># 假设我们有以下真实标签和预测结果</span></span><br><span class="line">y_true = np.array([<span class="number">2</span>, <span class="number">0</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">0</span>, <span class="number">1</span>])</span><br><span class="line">y_pred = np.array([<span class="number">0</span>, <span class="number">0</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">0</span>, <span class="number">2</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 计算准确率</span></span><br><span class="line">accuracy = accuracy_score(y_true, y_pred)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;准确率：&quot;</span>, accuracy)</span><br></pre></td></tr></table></figure>

<p><strong>输出：</strong></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">准确率： 0.6666666666666666</span><br></pre></td></tr></table></figure>



<h4 id="1-5-2精确率"><a href="#1-5-2精确率" class="headerlink" title="1.5.2精确率"></a>1.5.2精确率</h4><p>$\text{Precision} &#x3D; \frac{\text{TP} }{\text{TP}  + \text{FP} }$</p>
<p>对于数据误检概率</p>
<p>预测值的数量作为分母，真实值与预测值相同的数量作为分子</p>
<p><strong>案例：</strong></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">#精确率</span><br><span class="line">from sklearn.metrics import confusion_matrix,accuracy_score,precision_score</span><br><span class="line">import numpy as np</span><br><span class="line">import matplotlib.pyplot as plt</span><br><span class="line">import seaborn as sns</span><br><span class="line"></span><br><span class="line"># 假设我们有以下真实标签和预测结果</span><br><span class="line">y_true = np.array([2, 0, 2, 2, 0, 1])</span><br><span class="line">y_pred = np.array([0, 0, 2, 2, 0, 2])</span><br><span class="line"></span><br><span class="line">#0的精确率是2/3</span><br><span class="line">#1的精确率是0</span><br><span class="line">#2的精确率是2/3</span><br><span class="line"></span><br><span class="line">#三个精确率相加后除3，得出整个的精确率</span><br><span class="line"></span><br><span class="line"># 计算精确率</span><br><span class="line">precision = precision_score(y_true, y_pred, average=&#x27;macro&#x27;)</span><br><span class="line">print(&quot;精确率：&quot;, precision)</span><br></pre></td></tr></table></figure>

<p>输出：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">精确率： 0.4444444444444444</span><br></pre></td></tr></table></figure>



<h4 id="1-5-3召回率"><a href="#1-5-3召回率" class="headerlink" title="1.5.3召回率"></a>1.5.3召回率</h4><p>$\text{Precision} &#x3D; \frac{\text{TP} }{\text{TP}  + \text{FN} }$</p>
<p>对于数据漏检概率</p>
<p>真实值的数量作为分母，预测值与真实值同的数量作为分子</p>
<p>召回率关注的是模型捕捉正类样本的能力。在某些领域，如医疗诊断，召回率尤其重要，因为漏诊（假负例）的后果可能非常严重。</p>
<p><strong>案例：</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> confusion_matrix,accuracy_score,precision_score,recall_score</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> seaborn <span class="keyword">as</span> sns</span><br><span class="line"></span><br><span class="line"><span class="comment"># 假设我们有以下真实标签和预测结果</span></span><br><span class="line">y_true = np.array([<span class="number">2</span>, <span class="number">0</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">0</span>, <span class="number">1</span>])</span><br><span class="line">y_pred = np.array([<span class="number">0</span>, <span class="number">0</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">0</span>, <span class="number">2</span>])</span><br><span class="line"><span class="comment"># 0召回率：1</span></span><br><span class="line"><span class="comment"># 1召回率：0</span></span><br><span class="line"><span class="comment"># 2召回率：2/3</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 计算召回率</span></span><br><span class="line">recall = recall_score(y_true, y_pred, average=<span class="string">&#x27;macro&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;召回率：&quot;</span>, recall)</span><br></pre></td></tr></table></figure>

<p><strong>输出:</strong></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">召回率： 0.5555555555555555</span><br></pre></td></tr></table></figure>



<h4 id="1-5-4F1分数"><a href="#1-5-4F1分数" class="headerlink" title="1.5.4F1分数"></a>1.5.4F1分数</h4><p>$\text{F1 Score} &#x3D; 2*\frac{\text{Pecision}*\text{Recall} }{\text{Pecision}+\text{Recall} }$</p>
<p>F1分数在精确率和召回率都较高的算法上表现出色。它是一个综合指标，特别适用于那些对精确率和召回率都同样重视的场景</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">from sklearn.metrics import confusion_matrix,accuracy_score,precision_score,recall_score,f1_score</span><br><span class="line">import numpy as np</span><br><span class="line">import matplotlib.pyplot as plt</span><br><span class="line">import seaborn as sns</span><br><span class="line"></span><br><span class="line"># 假设我们有以下真实标签和预测结果</span><br><span class="line">y_true = np.array([2, 0, 2, 2, 0, 1])</span><br><span class="line">y_pred = np.array([0, 0, 2, 2, 0, 2])</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 计算F1分数</span><br><span class="line">f1 = f1_score(y_true, y_pred, average=&#x27;macro&#x27;)</span><br><span class="line">print(&quot;F1分数：&quot;, f1)</span><br></pre></td></tr></table></figure>

<p>输出：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">F1分数： 0.48888888888888893</span><br></pre></td></tr></table></figure>

<h4 id="1-5-5混淆矩阵"><a href="#1-5-5混淆矩阵" class="headerlink" title="1.5.5混淆矩阵"></a>1.5.5混淆矩阵</h4><p>混淆矩阵是评估分类问题的基础工具，它是一个表格，显示了分类算法的预测结果与真实标签之间的关系。对于二分类问题，混淆矩阵包含真正例（TP）、真负例（TN）、假正例（FP）和假负例（FN）。这些值是计算其他评估指标的基础。混淆矩阵不仅提供了一个直观的视觉表示，还允许我们深入了解模型在各个类别上的表现，特别是当处理不平衡数据集时，混淆矩阵可以揭示模型是否倾向于错误地将一个类别分类为另一个类别。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line">from sklearn.metrics import confusion_matrix,accuracy_score,precision_score,recall_score,f1_score</span><br><span class="line">import numpy as np</span><br><span class="line">import matplotlib.pyplot as plt</span><br><span class="line">import seaborn as sns</span><br><span class="line"></span><br><span class="line"># 假设我们有以下真实标签和预测结果</span><br><span class="line">y_true = np.array([2, 0, 2, 2, 0, 1])</span><br><span class="line">y_pred = np.array([0, 0, 2, 2, 0, 2])</span><br><span class="line"></span><br><span class="line"># 计算准确率</span><br><span class="line">accuracy = accuracy_score(y_true, y_pred)</span><br><span class="line">print(&quot;准确率：&quot;, accuracy)</span><br><span class="line"></span><br><span class="line"># 计算精确率</span><br><span class="line">precision = precision_score(y_true, y_pred, average=&#x27;macro&#x27;)</span><br><span class="line">print(&quot;精确率：&quot;, precision)</span><br><span class="line"></span><br><span class="line"># 计算召回率</span><br><span class="line">recall = recall_score(y_true, y_pred, average=&#x27;macro&#x27;)</span><br><span class="line">print(&quot;召回率：&quot;, recall)</span><br><span class="line"></span><br><span class="line"># 计算F1分数</span><br><span class="line">f1 = f1_score(y_true, y_pred, average=&#x27;macro&#x27;)</span><br><span class="line">print(&quot;F1分数：&quot;, f1)</span><br><span class="line"></span><br><span class="line"># 计算混淆矩阵</span><br><span class="line">cm = confusion_matrix(y_true, y_pred)</span><br><span class="line"></span><br><span class="line"># 使用Seaborn的heatmap函数来可视化混淆矩阵</span><br><span class="line">plt.figure(figsize=(8, 6))</span><br><span class="line">sns.heatmap(cm, annot=True, fmt=&#x27;d&#x27;, cmap=&#x27;Blues&#x27;)</span><br><span class="line">plt.xlabel(&#x27;Predicted labels&#x27;)</span><br><span class="line">plt.ylabel(&#x27;True labels&#x27;)</span><br><span class="line">plt.title(&#x27;Confusion Matrix&#x27;)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<h4 id="1-5-6ROC曲线和AUC值"><a href="#1-5-6ROC曲线和AUC值" class="headerlink" title="1.5.6ROC曲线和AUC值"></a>1.5.6ROC曲线和AUC值</h4><p>ROC曲线是一个性能度量，显示了在不同阈值设置下模型的真正例率（召回率）和假正例率的关系。AUC值表示ROC曲线下的面积，用于衡量模型的整体性能，AUC值越高，模型性能越好。ROC曲线和AUC值是评估模型区分不同类别能力的重要工具，尤其在二分类问题中非常实用。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><span class="line">from sklearn.metrics import roc_curve, roc_auc_score</span><br><span class="line">from sklearn.model_selection import train_test_split</span><br><span class="line">from sklearn.ensemble import RandomForestClassifier</span><br><span class="line">import matplotlib.pyplot as plt</span><br><span class="line">import numpy as np</span><br><span class="line"></span><br><span class="line"># 假设我们有一个数据集</span><br><span class="line">X = np.array([[0, 0], [1, 1], [2, 0], [2, 2], [0, 1]])</span><br><span class="line">y = np.array([1, 1, 0, 1, 0])</span><br><span class="line"></span><br><span class="line">plt.scatter(X[y == 0, 0], X[y == 0, 1], color=&#x27;red&#x27;, label=&#x27;Class 0&#x27;)</span><br><span class="line">plt.scatter(X[y == 1, 0], X[y == 1, 1], color=&#x27;blue&#x27;, label=&#x27;Class 1&#x27;)</span><br><span class="line">plt.xlabel(&#x27;Feature 1&#x27;)</span><br><span class="line">plt.ylabel(&#x27;Feature 2&#x27;)</span><br><span class="line">plt.legend()</span><br><span class="line">plt.title(&#x27;Data Points by Class&#x27;)</span><br><span class="line">plt.grid(True)</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line"># 划分训练集和测试集</span><br><span class="line">X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=42)</span><br><span class="line"></span><br><span class="line">print(&quot;--------训练样本-----------&quot;)</span><br><span class="line">print(X_train,y_train)</span><br><span class="line">print(&quot;--------测试样本-----------&quot;)</span><br><span class="line">print(X_test,y_test)</span><br><span class="line"></span><br><span class="line"># 训练一个随机森林分类器</span><br><span class="line">clf = RandomForestClassifier(n_estimators=100, random_state=42)</span><br><span class="line">clf.fit(X_train, y_train)</span><br><span class="line"></span><br><span class="line"># 预测概率</span><br><span class="line">y_scores = clf.predict_proba(X_test)[:, 1]</span><br><span class="line"></span><br><span class="line"># 计算ROC曲线和AUC值</span><br><span class="line">fpr, tpr, thresholds = roc_curve(y_test, y_scores)</span><br><span class="line">auc = roc_auc_score(y_test, y_scores)</span><br><span class="line"></span><br><span class="line"># 绘制ROC曲线</span><br><span class="line">plt.figure()</span><br><span class="line">plt.plot(fpr, tpr, color=&#x27;darkorange&#x27;, lw=2, label=&#x27;ROC curve (area = %0.2f)&#x27; % auc)</span><br><span class="line">plt.plot([0, 1], [0, 1], color=&#x27;navy&#x27;, lw=2, linestyle=&#x27;--&#x27;)</span><br><span class="line">plt.xlim([0.0, 1.0])</span><br><span class="line">plt.ylim([0.0, 1.05])</span><br><span class="line">plt.xlabel(&#x27;False Positive Rate&#x27;)</span><br><span class="line">plt.ylabel(&#x27;True Positive Rate&#x27;)</span><br><span class="line">plt.title(&#x27;Receiver Operating Characteristic&#x27;)</span><br><span class="line">plt.legend(loc=&quot;lower right&quot;)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<h3 id="1-6常用网络："><a href="#1-6常用网络：" class="headerlink" title="1.6常用网络："></a>1.6常用网络：</h3><p>使用前：需要将文件修改到指定为止</p>
<h4 id="1-6-1GoogLeNet"><a href="#1-6-1GoogLeNet" class="headerlink" title="1.6.1GoogLeNet"></a>1.6.1GoogLeNet</h4><p>搭建模型：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br></pre></td><td class="code"><pre><span class="line">import torch.nn as nn</span><br><span class="line">import torch</span><br><span class="line">import torch.nn.functional as F</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">class GoogLeNet(nn.Module):</span><br><span class="line">    def __init__(self, num_classes=1000, aux_logits=True, init_weights=False):</span><br><span class="line">        super(GoogLeNet, self).__init__()</span><br><span class="line">        self.aux_logits = aux_logits</span><br><span class="line"></span><br><span class="line">        self.conv1 = BasicConv2d(3, 64, kernel_size=7, stride=2, padding=3)</span><br><span class="line">        self.maxpool1 = nn.MaxPool2d(3, stride=2, ceil_mode=True)  # ceil_mode=true 得到的小数向上取整 ceil_mode=false 向下取整</span><br><span class="line"></span><br><span class="line">        self.conv2 = BasicConv2d(64, 64, kernel_size=1)  # 第一个64是输入特征矩阵深度，第二个64是卷积核的个数</span><br><span class="line">        self.conv3 = BasicConv2d(64, 192, kernel_size=3, padding=1)</span><br><span class="line">        self.maxpool2 = nn.MaxPool2d(3, stride=2, ceil_mode=True)</span><br><span class="line"></span><br><span class="line">        self.inception3a = Inception(192, 64, 96, 128, 16, 32, 32)  # 第一个参数是输入特征矩阵深度，后面的参数都是按照表格中的参数</span><br><span class="line">        self.inception3b = Inception(256, 128, 128, 192, 32, 96, 64)</span><br><span class="line">        self.maxpool3 = nn.MaxPool2d(3, stride=2, ceil_mode=True)</span><br><span class="line"></span><br><span class="line">        self.inception4a = Inception(480, 192, 96, 208, 16, 48, 64)</span><br><span class="line">        self.inception4b = Inception(512, 160, 112, 224, 24, 64, 64)</span><br><span class="line">        self.inception4c = Inception(512, 128, 128, 256, 24, 64, 64)</span><br><span class="line">        self.inception4d = Inception(512, 112, 144, 288, 32, 64, 64)</span><br><span class="line">        self.inception4e = Inception(528, 256, 160, 320, 32, 128, 128)</span><br><span class="line">        self.maxpool4 = nn.MaxPool2d(3, stride=2, ceil_mode=True)</span><br><span class="line"></span><br><span class="line">        self.inception5a = Inception(832, 256, 160, 320, 32, 128, 128)</span><br><span class="line">        self.inception5b = Inception(832, 384, 192, 384, 48, 128, 128)</span><br><span class="line"></span><br><span class="line">        if self.aux_logits:</span><br><span class="line">            self.aux1 = InceptionAux(512, num_classes)  # 4a的输出</span><br><span class="line">            self.aux2 = InceptionAux(528, num_classes)  # 4d的输出</span><br><span class="line"></span><br><span class="line">        self.avgpool = nn.AdaptiveAvgPool2d(</span><br><span class="line">            (1, 1))  # 自适应平均池化下采样操作（1，1）是输出特征矩阵的高和宽，好处就是无论输入特征矩阵的高和宽是什么样的大小，我们都能够我们所指定的一个特征矩阵的高和宽</span><br><span class="line">        self.dropout = nn.Dropout(0.4)</span><br><span class="line">        self.fc = nn.Linear(1024, num_classes)</span><br><span class="line">        if init_weights:</span><br><span class="line">            self._initialize_weights()</span><br><span class="line"></span><br><span class="line">    def forward(self, x):  # 网络的正向传播过程</span><br><span class="line">        # N x 3 x 224 x 224</span><br><span class="line">        x = self.conv1(x)</span><br><span class="line">        # N x 64 x 112 x 112</span><br><span class="line">        x = self.maxpool1(x)</span><br><span class="line">        # N x 64 x 56 x 56</span><br><span class="line">        x = self.conv2(x)</span><br><span class="line">        # N x 64 x 56 x 56</span><br><span class="line">        x = self.conv3(x)</span><br><span class="line">        # N x 192 x 56 x 56</span><br><span class="line">        x = self.maxpool2(x)</span><br><span class="line"></span><br><span class="line">        # N x 192 x 28 x 28</span><br><span class="line">        x = self.inception3a(x)</span><br><span class="line">        # N x 256 x 28 x 28</span><br><span class="line">        x = self.inception3b(x)</span><br><span class="line">        # N x 480 x 28 x 28</span><br><span class="line">        x = self.maxpool3(x)</span><br><span class="line">        # N x 480 x 14 x 14</span><br><span class="line">        x = self.inception4a(x)</span><br><span class="line">        # N x 512 x 14 x 14</span><br><span class="line">        if self.training and self.aux_logits:  # eval model lose this layer</span><br><span class="line">            aux1 = self.aux1(x)</span><br><span class="line"></span><br><span class="line">        x = self.inception4b(x)</span><br><span class="line">        # N x 512 x 14 x 14</span><br><span class="line">        x = self.inception4c(x)</span><br><span class="line">        # N x 512 x 14 x 14</span><br><span class="line">        x = self.inception4d(x)</span><br><span class="line">        # N x 528 x 14 x 14</span><br><span class="line">        if self.training and self.aux_logits:  # eval model lose this layer</span><br><span class="line">            aux2 = self.aux2(x)</span><br><span class="line"></span><br><span class="line">        x = self.inception4e(x)</span><br><span class="line">        # N x 832 x 14 x 14</span><br><span class="line">        x = self.maxpool4(x)</span><br><span class="line">        # N x 832 x 7 x 7</span><br><span class="line">        x = self.inception5a(x)</span><br><span class="line">        # N x 832 x 7 x 7</span><br><span class="line">        x = self.inception5b(x)</span><br><span class="line">        # N x 1024 x 7 x 7</span><br><span class="line"></span><br><span class="line">        x = self.avgpool(x)</span><br><span class="line">        # N x 1024 x 1 x 1</span><br><span class="line">        x = torch.flatten(x, 1)</span><br><span class="line">        # N x 1024</span><br><span class="line">        x = self.dropout(x)</span><br><span class="line">        x = self.fc(x)</span><br><span class="line">        # N x 1000 (num_classes)</span><br><span class="line">        if self.training and self.aux_logits:  # eval model lose this layer</span><br><span class="line">            return x, aux2, aux1</span><br><span class="line">        return x</span><br><span class="line"></span><br><span class="line">    def _initialize_weights(self):</span><br><span class="line">        for m in self.modules():</span><br><span class="line">            if isinstance(m, nn.Conv2d):</span><br><span class="line">                nn.init.kaiming_normal_(m.weight, mode=&#x27;fan_out&#x27;, nonlinearity=&#x27;relu&#x27;)</span><br><span class="line">                if m.bias is not None:</span><br><span class="line">                    nn.init.constant_(m.bias, 0)</span><br><span class="line">            elif isinstance(m, nn.Linear):</span><br><span class="line">                nn.init.normal_(m.weight, 0, 0.01)</span><br><span class="line">                nn.init.constant_(m.bias, 0)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">class Inception(nn.Module):  # Inception模板</span><br><span class="line">    def __init__(self, in_channels, ch1x1, ch3x3red, ch3x3, ch5x5red, ch5x5, pool_proj):</span><br><span class="line">        super(Inception, self).__init__()</span><br><span class="line"></span><br><span class="line">        self.branch1 = BasicConv2d(in_channels, ch1x1, kernel_size=1)</span><br><span class="line"></span><br><span class="line">        self.branch2 = nn.Sequential(  # 传入非关键字的参数</span><br><span class="line">            BasicConv2d(in_channels, ch3x3red, kernel_size=1),</span><br><span class="line">            BasicConv2d(ch3x3red, ch3x3, kernel_size=3, padding=1)  # 保证输出特征矩阵大小等于输入大小</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">        self.branch3 = nn.Sequential(</span><br><span class="line">            BasicConv2d(in_channels, ch5x5red, kernel_size=1),</span><br><span class="line">            # 在官方的实现中，其实是3x3的kernel并不是5x5，这里我也懒得改了，具体可以参考下面的issue</span><br><span class="line">            # Please see https://github.com/pytorch/vision/issues/906 for details.</span><br><span class="line">            BasicConv2d(ch5x5red, ch5x5, kernel_size=5, padding=2)  # 保证输出大小等于输入大小</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">        self.branch4 = nn.Sequential(</span><br><span class="line">            nn.MaxPool2d(kernel_size=3, stride=1, padding=1),</span><br><span class="line">            BasicConv2d(in_channels, pool_proj, kernel_size=1)</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">    def forward(self, x):  # 正向传播过程</span><br><span class="line">        branch1 = self.branch1(x)</span><br><span class="line">        branch2 = self.branch2(x)</span><br><span class="line">        branch3 = self.branch3(x)</span><br><span class="line">        branch4 = self.branch4(x)</span><br><span class="line"></span><br><span class="line">        outputs = [branch1, branch2, branch3, branch4]  # 将4个分支的输出放入到一个列表当中</span><br><span class="line">        return torch.cat(outputs, 1)  # 通过cat函数将这4个分支进行合并，在第一个维度也就是channel深度进行合并</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">class InceptionAux(nn.Module):  # 定义辅助分类器模板</span><br><span class="line">    def __init__(self, in_channels, num_classes):</span><br><span class="line">        super(InceptionAux, self).__init__()</span><br><span class="line">        self.averagePool = nn.AvgPool2d(kernel_size=5, stride=3)</span><br><span class="line">        self.conv = BasicConv2d(in_channels, 128, kernel_size=1)  # output[batch, 128, 4, 4]</span><br><span class="line"></span><br><span class="line">        self.fc1 = nn.Linear(2048, 1024)  # 2048是展平后的节点个数128*4*4</span><br><span class="line">        self.fc2 = nn.Linear(1024, num_classes)</span><br><span class="line"></span><br><span class="line">    def forward(self, x):</span><br><span class="line">        # aux1: N x 512 x 14 x 14, aux2: N x 528 x 14 x 14 输入特征矩阵的维度</span><br><span class="line">        x = self.averagePool(x)</span><br><span class="line">        # aux1: N x 512 x 4 x 4, aux2: N x 528 x 4 x 4</span><br><span class="line">        x = self.conv(x)</span><br><span class="line">        # N x 128 x 4 x 4</span><br><span class="line">        x = torch.flatten(x, 1)</span><br><span class="line">        x = F.dropout(x, 0.5, training=self.training)  # 当我们实例化一个模型model后，可以通过model.train()和model.eval()来控制模型的状态，</span><br><span class="line">        # 在model.train()模式下self.training=True，在model.eval()模式下self.training=False</span><br><span class="line">        # N x 2048</span><br><span class="line">        x = F.relu(self.fc1(x), inplace=True)</span><br><span class="line">        x = F.dropout(x, 0.5, training=self.training)</span><br><span class="line">        # N x 1024</span><br><span class="line">        x = self.fc2(x)</span><br><span class="line">        # N x num_classes</span><br><span class="line">        return x</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">class BasicConv2d(nn.Module):  # 卷积模板文件</span><br><span class="line">    def __init__(self, in_channels, out_channels, **kwargs):</span><br><span class="line">        super(BasicConv2d, self).__init__()</span><br><span class="line">        self.conv = nn.Conv2d(in_channels, out_channels, **kwargs)</span><br><span class="line">        self.relu = nn.ReLU(inplace=True)</span><br><span class="line"></span><br><span class="line">    def forward(self, x):  # 正向传播过程</span><br><span class="line">        x = self.conv(x)</span><br><span class="line">        x = self.relu(x)</span><br><span class="line">        return x</span><br></pre></td></tr></table></figure>

<p>训练：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br></pre></td><td class="code"><pre><span class="line">import torch.nn as nn</span><br><span class="line">import torch</span><br><span class="line">import torch.nn.functional as F</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">class GoogLeNet(nn.Module):</span><br><span class="line">    def __init__(self, num_classes=1000, aux_logits=True, init_weights=False):</span><br><span class="line">        super(GoogLeNet, self).__init__()</span><br><span class="line">        self.aux_logits = aux_logits</span><br><span class="line"></span><br><span class="line">        self.conv1 = BasicConv2d(3, 64, kernel_size=7, stride=2, padding=3)</span><br><span class="line">        self.maxpool1 = nn.MaxPool2d(3, stride=2, ceil_mode=True)  # ceil_mode=true 得到的小数向上取整 ceil_mode=false 向下取整</span><br><span class="line"></span><br><span class="line">        self.conv2 = BasicConv2d(64, 64, kernel_size=1)  # 第一个64是输入特征矩阵深度，第二个64是卷积核的个数</span><br><span class="line">        self.conv3 = BasicConv2d(64, 192, kernel_size=3, padding=1)</span><br><span class="line">        self.maxpool2 = nn.MaxPool2d(3, stride=2, ceil_mode=True)</span><br><span class="line"></span><br><span class="line">        self.inception3a = Inception(192, 64, 96, 128, 16, 32, 32)  # 第一个参数是输入特征矩阵深度，后面的参数都是按照表格中的参数</span><br><span class="line">        self.inception3b = Inception(256, 128, 128, 192, 32, 96, 64)</span><br><span class="line">        self.maxpool3 = nn.MaxPool2d(3, stride=2, ceil_mode=True)</span><br><span class="line"></span><br><span class="line">        self.inception4a = Inception(480, 192, 96, 208, 16, 48, 64)</span><br><span class="line">        self.inception4b = Inception(512, 160, 112, 224, 24, 64, 64)</span><br><span class="line">        self.inception4c = Inception(512, 128, 128, 256, 24, 64, 64)</span><br><span class="line">        self.inception4d = Inception(512, 112, 144, 288, 32, 64, 64)</span><br><span class="line">        self.inception4e = Inception(528, 256, 160, 320, 32, 128, 128)</span><br><span class="line">        self.maxpool4 = nn.MaxPool2d(3, stride=2, ceil_mode=True)</span><br><span class="line"></span><br><span class="line">        self.inception5a = Inception(832, 256, 160, 320, 32, 128, 128)</span><br><span class="line">        self.inception5b = Inception(832, 384, 192, 384, 48, 128, 128)</span><br><span class="line"></span><br><span class="line">        if self.aux_logits:</span><br><span class="line">            self.aux1 = InceptionAux(512, num_classes)  # 4a的输出</span><br><span class="line">            self.aux2 = InceptionAux(528, num_classes)  # 4d的输出</span><br><span class="line"></span><br><span class="line">        self.avgpool = nn.AdaptiveAvgPool2d(</span><br><span class="line">            (1, 1))  # 自适应平均池化下采样操作（1，1）是输出特征矩阵的高和宽，好处就是无论输入特征矩阵的高和宽是什么样的大小，我们都能够我们所指定的一个特征矩阵的高和宽</span><br><span class="line">        self.dropout = nn.Dropout(0.4)</span><br><span class="line">        self.fc = nn.Linear(1024, num_classes)</span><br><span class="line">        if init_weights:</span><br><span class="line">            self._initialize_weights()</span><br><span class="line"></span><br><span class="line">    def forward(self, x):  # 网络的正向传播过程</span><br><span class="line">        # N x 3 x 224 x 224</span><br><span class="line">        x = self.conv1(x)</span><br><span class="line">        # N x 64 x 112 x 112</span><br><span class="line">        x = self.maxpool1(x)</span><br><span class="line">        # N x 64 x 56 x 56</span><br><span class="line">        x = self.conv2(x)</span><br><span class="line">        # N x 64 x 56 x 56</span><br><span class="line">        x = self.conv3(x)</span><br><span class="line">        # N x 192 x 56 x 56</span><br><span class="line">        x = self.maxpool2(x)</span><br><span class="line"></span><br><span class="line">        # N x 192 x 28 x 28</span><br><span class="line">        x = self.inception3a(x)</span><br><span class="line">        # N x 256 x 28 x 28</span><br><span class="line">        x = self.inception3b(x)</span><br><span class="line">        # N x 480 x 28 x 28</span><br><span class="line">        x = self.maxpool3(x)</span><br><span class="line">        # N x 480 x 14 x 14</span><br><span class="line">        x = self.inception4a(x)</span><br><span class="line">        # N x 512 x 14 x 14</span><br><span class="line">        if self.training and self.aux_logits:  # eval model lose this layer</span><br><span class="line">            aux1 = self.aux1(x)</span><br><span class="line"></span><br><span class="line">        x = self.inception4b(x)</span><br><span class="line">        # N x 512 x 14 x 14</span><br><span class="line">        x = self.inception4c(x)</span><br><span class="line">        # N x 512 x 14 x 14</span><br><span class="line">        x = self.inception4d(x)</span><br><span class="line">        # N x 528 x 14 x 14</span><br><span class="line">        if self.training and self.aux_logits:  # eval model lose this layer</span><br><span class="line">            aux2 = self.aux2(x)</span><br><span class="line"></span><br><span class="line">        x = self.inception4e(x)</span><br><span class="line">        # N x 832 x 14 x 14</span><br><span class="line">        x = self.maxpool4(x)</span><br><span class="line">        # N x 832 x 7 x 7</span><br><span class="line">        x = self.inception5a(x)</span><br><span class="line">        # N x 832 x 7 x 7</span><br><span class="line">        x = self.inception5b(x)</span><br><span class="line">        # N x 1024 x 7 x 7</span><br><span class="line"></span><br><span class="line">        x = self.avgpool(x)</span><br><span class="line">        # N x 1024 x 1 x 1</span><br><span class="line">        x = torch.flatten(x, 1)</span><br><span class="line">        # N x 1024</span><br><span class="line">        x = self.dropout(x)</span><br><span class="line">        x = self.fc(x)</span><br><span class="line">        # N x 1000 (num_classes)</span><br><span class="line">        if self.training and self.aux_logits:  # eval model lose this layer</span><br><span class="line">            return x, aux2, aux1</span><br><span class="line">        return x</span><br><span class="line"></span><br><span class="line">    def _initialize_weights(self):</span><br><span class="line">        for m in self.modules():</span><br><span class="line">            if isinstance(m, nn.Conv2d):</span><br><span class="line">                nn.init.kaiming_normal_(m.weight, mode=&#x27;fan_out&#x27;, nonlinearity=&#x27;relu&#x27;)</span><br><span class="line">                if m.bias is not None:</span><br><span class="line">                    nn.init.constant_(m.bias, 0)</span><br><span class="line">            elif isinstance(m, nn.Linear):</span><br><span class="line">                nn.init.normal_(m.weight, 0, 0.01)</span><br><span class="line">                nn.init.constant_(m.bias, 0)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">class Inception(nn.Module):  # Inception模板</span><br><span class="line">    def __init__(self, in_channels, ch1x1, ch3x3red, ch3x3, ch5x5red, ch5x5, pool_proj):</span><br><span class="line">        super(Inception, self).__init__()</span><br><span class="line"></span><br><span class="line">        self.branch1 = BasicConv2d(in_channels, ch1x1, kernel_size=1)</span><br><span class="line"></span><br><span class="line">        self.branch2 = nn.Sequential(  # 传入非关键字的参数</span><br><span class="line">            BasicConv2d(in_channels, ch3x3red, kernel_size=1),</span><br><span class="line">            BasicConv2d(ch3x3red, ch3x3, kernel_size=3, padding=1)  # 保证输出特征矩阵大小等于输入大小</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">        self.branch3 = nn.Sequential(</span><br><span class="line">            BasicConv2d(in_channels, ch5x5red, kernel_size=1),</span><br><span class="line">            # 在官方的实现中，其实是3x3的kernel并不是5x5，这里我也懒得改了，具体可以参考下面的issue</span><br><span class="line">            # Please see https://github.com/pytorch/vision/issues/906 for details.</span><br><span class="line">            BasicConv2d(ch5x5red, ch5x5, kernel_size=5, padding=2)  # 保证输出大小等于输入大小</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">        self.branch4 = nn.Sequential(</span><br><span class="line">            nn.MaxPool2d(kernel_size=3, stride=1, padding=1),</span><br><span class="line">            BasicConv2d(in_channels, pool_proj, kernel_size=1)</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">    def forward(self, x):  # 正向传播过程</span><br><span class="line">        branch1 = self.branch1(x)</span><br><span class="line">        branch2 = self.branch2(x)</span><br><span class="line">        branch3 = self.branch3(x)</span><br><span class="line">        branch4 = self.branch4(x)</span><br><span class="line"></span><br><span class="line">        outputs = [branch1, branch2, branch3, branch4]  # 将4个分支的输出放入到一个列表当中</span><br><span class="line">        return torch.cat(outputs, 1)  # 通过cat函数将这4个分支进行合并，在第一个维度也就是channel深度进行合并</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">class InceptionAux(nn.Module):  # 定义辅助分类器模板</span><br><span class="line">    def __init__(self, in_channels, num_classes):</span><br><span class="line">        super(InceptionAux, self).__init__()</span><br><span class="line">        self.averagePool = nn.AvgPool2d(kernel_size=5, stride=3)</span><br><span class="line">        self.conv = BasicConv2d(in_channels, 128, kernel_size=1)  # output[batch, 128, 4, 4]</span><br><span class="line"></span><br><span class="line">        self.fc1 = nn.Linear(2048, 1024)  # 2048是展平后的节点个数128*4*4</span><br><span class="line">        self.fc2 = nn.Linear(1024, num_classes)</span><br><span class="line"></span><br><span class="line">    def forward(self, x):</span><br><span class="line">        # aux1: N x 512 x 14 x 14, aux2: N x 528 x 14 x 14 输入特征矩阵的维度</span><br><span class="line">        x = self.averagePool(x)</span><br><span class="line">        # aux1: N x 512 x 4 x 4, aux2: N x 528 x 4 x 4</span><br><span class="line">        x = self.conv(x)</span><br><span class="line">        # N x 128 x 4 x 4</span><br><span class="line">        x = torch.flatten(x, 1)</span><br><span class="line">        x = F.dropout(x, 0.5, training=self.training)  # 当我们实例化一个模型model后，可以通过model.train()和model.eval()来控制模型的状态，</span><br><span class="line">        # 在model.train()模式下self.training=True，在model.eval()模式下self.training=False</span><br><span class="line">        # N x 2048</span><br><span class="line">        x = F.relu(self.fc1(x), inplace=True)</span><br><span class="line">        x = F.dropout(x, 0.5, training=self.training)</span><br><span class="line">        # N x 1024</span><br><span class="line">        x = self.fc2(x)</span><br><span class="line">        # N x num_classes</span><br><span class="line">        return x</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">class BasicConv2d(nn.Module):  # 卷积模板文件</span><br><span class="line">    def __init__(self, in_channels, out_channels, **kwargs):</span><br><span class="line">        super(BasicConv2d, self).__init__()</span><br><span class="line">        self.conv = nn.Conv2d(in_channels, out_channels, **kwargs)</span><br><span class="line">        self.relu = nn.ReLU(inplace=True)</span><br><span class="line"></span><br><span class="line">    def forward(self, x):  # 正向传播过程</span><br><span class="line">        x = self.conv(x)</span><br><span class="line">        x = self.relu(x)</span><br><span class="line">        return x</span><br></pre></td></tr></table></figure>

<p>测试：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br></pre></td><td class="code"><pre><span class="line">import os</span><br><span class="line">import json</span><br><span class="line">import torch</span><br><span class="line">from PIL import Image</span><br><span class="line">from torchvision import transforms</span><br><span class="line">import matplotlib.pyplot as plt</span><br><span class="line">from model import GoogLeNet</span><br><span class="line">import os</span><br><span class="line"></span><br><span class="line">os.environ[&quot;KMP_DUPLICATE_LIB_OK&quot;] = &quot;TRUE&quot;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def main():</span><br><span class="line">    device = torch.device(&quot;cuda:0&quot; if torch.cuda.is_available() else &quot;cpu&quot;)</span><br><span class="line"></span><br><span class="line">    data_transform = transforms.Compose(  # 依然是对数据先进行预处理</span><br><span class="line">        [transforms.Resize((224, 224)),</span><br><span class="line">         transforms.ToTensor(),</span><br><span class="line">         transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])</span><br><span class="line"></span><br><span class="line">    # load image</span><br><span class="line">    img_path = r&quot;D:\华清补习文件\code\每日笔记\goole.act\flower_photos\daisy\5794835_d15905c7c8_n.jpg&quot;</span><br><span class="line">    assert os.path.exists(img_path), &quot;file: &#x27;&#123;&#125;&#x27; dose not exist.&quot;.format(img_path)</span><br><span class="line">    img = Image.open(img_path)  # 直接使用PIL库载入一张图像</span><br><span class="line"></span><br><span class="line">    plt.imshow(img)  # 简单展示一下这张图片</span><br><span class="line">    # [N, C, H, W]</span><br><span class="line">    img = data_transform(img)  # 对图片进行预处理</span><br><span class="line">    # expand batch dimension</span><br><span class="line">    img = torch.unsqueeze(img, dim=0)  # 扩充一个维度，添加一个batch维度</span><br><span class="line"></span><br><span class="line">    class_indict=&#123;&quot;0&quot;: &quot;daisies&quot;, &quot;1&quot;: &quot;dandelion&quot;, &quot;2&quot;: &quot;roses&quot;, &quot;3&quot;: &quot;sunflowers&quot;, &quot;4&quot;: &quot;tulips&quot;&#125;</span><br><span class="line"></span><br><span class="line">    # create model</span><br><span class="line">    model = GoogLeNet(num_classes=5)                                                                                                                                                         (num_classes=5).to(device)  # 初始化我们的网络</span><br><span class="line"></span><br><span class="line">    # load model weights</span><br><span class="line">    weights_path = r&quot;D:\华清补习文件\code\每日笔记\model\googlenet_flower.pth&quot;</span><br><span class="line">    assert os.path.exists(weights_path), &quot;file: &#x27;&#123;&#125;&#x27; dose not exist.&quot;.format(weights_path)</span><br><span class="line">    model.load_state_dict(torch.load(weights_path))  # 载入我们的网络模型</span><br><span class="line"></span><br><span class="line">    model.eval()  # 进入eval模式，没有dropout的那个</span><br><span class="line">    with torch.no_grad():  # 不跟踪变量的损失梯度</span><br><span class="line">        # predict class</span><br><span class="line">        output = torch.squeeze(model(img.to(device))).cpu()  # 将数据通过model进行正向传播得到输出</span><br><span class="line">        # squeeze将输出进行压缩，把第一个维度的batch压缩掉了</span><br><span class="line">        predict = torch.softmax(output, dim=0)  # softmax得到概率分布</span><br><span class="line">        predict_cla = torch.argmax(predict).numpy()  # 概率最大处所对应的索引值</span><br><span class="line"></span><br><span class="line">    print_res = &quot;class: &#123;&#125;   prob: &#123;:.3&#125;&quot;.format(class_indict[str(predict_cla)],</span><br><span class="line">                                                 predict[predict_cla].numpy())</span><br><span class="line">    # 打印预测名称，已经对应类别的概率</span><br><span class="line">    plt.title(print_res)</span><br><span class="line">    for i in range(len(predict)):</span><br><span class="line">        print(&quot;class: &#123;:10&#125;   prob: &#123;:.3&#125;&quot;.format(class_indict[str(i)],</span><br><span class="line">                                                  predict[i].numpy()))</span><br><span class="line">    plt.show()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">if __name__ == &#x27;__main__&#x27;:</span><br><span class="line">    main()</span><br></pre></td></tr></table></figure>



<h4 id="1-6-2MobileNet"><a href="#1-6-2MobileNet" class="headerlink" title="1.6.2MobileNet"></a>1.6.2MobileNet</h4><p>轻量化适用于在移动设备上</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br></pre></td><td class="code"><pre><span class="line">import torch.nn as nn</span><br><span class="line">import torch</span><br><span class="line">import torch.nn.functional as F</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">class GoogLeNet(nn.Module):</span><br><span class="line">    def __init__(self, num_classes=1000, aux_logits=True, init_weights=False):</span><br><span class="line">        super(GoogLeNet, self).__init__()</span><br><span class="line">        self.aux_logits = aux_logits</span><br><span class="line"></span><br><span class="line">        self.conv1 = BasicConv2d(3, 64, kernel_size=7, stride=2, padding=3)</span><br><span class="line">        self.maxpool1 = nn.MaxPool2d(3, stride=2, ceil_mode=True)  # ceil_mode=true 得到的小数向上取整 ceil_mode=false 向下取整</span><br><span class="line"></span><br><span class="line">        self.conv2 = BasicConv2d(64, 64, kernel_size=1)  # 第一个64是输入特征矩阵深度，第二个64是卷积核的个数</span><br><span class="line">        self.conv3 = BasicConv2d(64, 192, kernel_size=3, padding=1)</span><br><span class="line">        self.maxpool2 = nn.MaxPool2d(3, stride=2, ceil_mode=True)</span><br><span class="line"></span><br><span class="line">        self.inception3a = Inception(192, 64, 96, 128, 16, 32, 32)  # 第一个参数是输入特征矩阵深度，后面的参数都是按照表格中的参数</span><br><span class="line">        self.inception3b = Inception(256, 128, 128, 192, 32, 96, 64)</span><br><span class="line">        self.maxpool3 = nn.MaxPool2d(3, stride=2, ceil_mode=True)</span><br><span class="line"></span><br><span class="line">        self.inception4a = Inception(480, 192, 96, 208, 16, 48, 64)</span><br><span class="line">        self.inception4b = Inception(512, 160, 112, 224, 24, 64, 64)</span><br><span class="line">        self.inception4c = Inception(512, 128, 128, 256, 24, 64, 64)</span><br><span class="line">        self.inception4d = Inception(512, 112, 144, 288, 32, 64, 64)</span><br><span class="line">        self.inception4e = Inception(528, 256, 160, 320, 32, 128, 128)</span><br><span class="line">        self.maxpool4 = nn.MaxPool2d(3, stride=2, ceil_mode=True)</span><br><span class="line"></span><br><span class="line">        self.inception5a = Inception(832, 256, 160, 320, 32, 128, 128)</span><br><span class="line">        self.inception5b = Inception(832, 384, 192, 384, 48, 128, 128)</span><br><span class="line"></span><br><span class="line">        if self.aux_logits:</span><br><span class="line">            self.aux1 = InceptionAux(512, num_classes)  # 4a的输出</span><br><span class="line">            self.aux2 = InceptionAux(528, num_classes)  # 4d的输出</span><br><span class="line"></span><br><span class="line">        self.avgpool = nn.AdaptiveAvgPool2d(</span><br><span class="line">            (1, 1))  # 自适应平均池化下采样操作（1，1）是输出特征矩阵的高和宽，好处就是无论输入特征矩阵的高和宽是什么样的大小，我们都能够我们所指定的一个特征矩阵的高和宽</span><br><span class="line">        self.dropout = nn.Dropout(0.4)</span><br><span class="line">        self.fc = nn.Linear(1024, num_classes)</span><br><span class="line">        if init_weights:</span><br><span class="line">            self._initialize_weights()</span><br><span class="line"></span><br><span class="line">    def forward(self, x):  # 网络的正向传播过程</span><br><span class="line">        # N x 3 x 224 x 224</span><br><span class="line">        x = self.conv1(x)</span><br><span class="line">        # N x 64 x 112 x 112</span><br><span class="line">        x = self.maxpool1(x)</span><br><span class="line">        # N x 64 x 56 x 56</span><br><span class="line">        x = self.conv2(x)</span><br><span class="line">        # N x 64 x 56 x 56</span><br><span class="line">        x = self.conv3(x)</span><br><span class="line">        # N x 192 x 56 x 56</span><br><span class="line">        x = self.maxpool2(x)</span><br><span class="line"></span><br><span class="line">        # N x 192 x 28 x 28</span><br><span class="line">        x = self.inception3a(x)</span><br><span class="line">        # N x 256 x 28 x 28</span><br><span class="line">        x = self.inception3b(x)</span><br><span class="line">        # N x 480 x 28 x 28</span><br><span class="line">        x = self.maxpool3(x)</span><br><span class="line">        # N x 480 x 14 x 14</span><br><span class="line">        x = self.inception4a(x)</span><br><span class="line">        # N x 512 x 14 x 14</span><br><span class="line">        if self.training and self.aux_logits:  # eval model lose this layer</span><br><span class="line">            aux1 = self.aux1(x)</span><br><span class="line"></span><br><span class="line">        x = self.inception4b(x)</span><br><span class="line">        # N x 512 x 14 x 14</span><br><span class="line">        x = self.inception4c(x)</span><br><span class="line">        # N x 512 x 14 x 14</span><br><span class="line">        x = self.inception4d(x)</span><br><span class="line">        # N x 528 x 14 x 14</span><br><span class="line">        if self.training and self.aux_logits:  # eval model lose this layer</span><br><span class="line">            aux2 = self.aux2(x)</span><br><span class="line"></span><br><span class="line">        x = self.inception4e(x)</span><br><span class="line">        # N x 832 x 14 x 14</span><br><span class="line">        x = self.maxpool4(x)</span><br><span class="line">        # N x 832 x 7 x 7</span><br><span class="line">        x = self.inception5a(x)</span><br><span class="line">        # N x 832 x 7 x 7</span><br><span class="line">        x = self.inception5b(x)</span><br><span class="line">        # N x 1024 x 7 x 7</span><br><span class="line"></span><br><span class="line">        x = self.avgpool(x)</span><br><span class="line">        # N x 1024 x 1 x 1</span><br><span class="line">        x = torch.flatten(x, 1)</span><br><span class="line">        # N x 1024</span><br><span class="line">        x = self.dropout(x)</span><br><span class="line">        x = self.fc(x)</span><br><span class="line">        # N x 1000 (num_classes)</span><br><span class="line">        if self.training and self.aux_logits:  # eval model lose this layer</span><br><span class="line">            return x, aux2, aux1</span><br><span class="line">        return x</span><br><span class="line"></span><br><span class="line">    def _initialize_weights(self):</span><br><span class="line">        for m in self.modules():</span><br><span class="line">            if isinstance(m, nn.Conv2d):</span><br><span class="line">                nn.init.kaiming_normal_(m.weight, mode=&#x27;fan_out&#x27;, nonlinearity=&#x27;relu&#x27;)</span><br><span class="line">                if m.bias is not None:</span><br><span class="line">                    nn.init.constant_(m.bias, 0)</span><br><span class="line">            elif isinstance(m, nn.Linear):</span><br><span class="line">                nn.init.normal_(m.weight, 0, 0.01)</span><br><span class="line">                nn.init.constant_(m.bias, 0)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">class Inception(nn.Module):  # Inception模板</span><br><span class="line">    def __init__(self, in_channels, ch1x1, ch3x3red, ch3x3, ch5x5red, ch5x5, pool_proj):</span><br><span class="line">        super(Inception, self).__init__()</span><br><span class="line"></span><br><span class="line">        self.branch1 = BasicConv2d(in_channels, ch1x1, kernel_size=1)</span><br><span class="line"></span><br><span class="line">        self.branch2 = nn.Sequential(  # 传入非关键字的参数</span><br><span class="line">            BasicConv2d(in_channels, ch3x3red, kernel_size=1),</span><br><span class="line">            BasicConv2d(ch3x3red, ch3x3, kernel_size=3, padding=1)  # 保证输出特征矩阵大小等于输入大小</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">        self.branch3 = nn.Sequential(</span><br><span class="line">            BasicConv2d(in_channels, ch5x5red, kernel_size=1),</span><br><span class="line">            # 在官方的实现中，其实是3x3的kernel并不是5x5，这里我也懒得改了，具体可以参考下面的issue</span><br><span class="line">            # Please see https://github.com/pytorch/vision/issues/906 for details.</span><br><span class="line">            BasicConv2d(ch5x5red, ch5x5, kernel_size=5, padding=2)  # 保证输出大小等于输入大小</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">        self.branch4 = nn.Sequential(</span><br><span class="line">            nn.MaxPool2d(kernel_size=3, stride=1, padding=1),</span><br><span class="line">            BasicConv2d(in_channels, pool_proj, kernel_size=1)</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">    def forward(self, x):  # 正向传播过程</span><br><span class="line">        branch1 = self.branch1(x)</span><br><span class="line">        branch2 = self.branch2(x)</span><br><span class="line">        branch3 = self.branch3(x)</span><br><span class="line">        branch4 = self.branch4(x)</span><br><span class="line"></span><br><span class="line">        outputs = [branch1, branch2, branch3, branch4]  # 将4个分支的输出放入到一个列表当中</span><br><span class="line">        return torch.cat(outputs, 1)  # 通过cat函数将这4个分支进行合并，在第一个维度也就是channel深度进行合并</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">class InceptionAux(nn.Module):  # 定义辅助分类器模板</span><br><span class="line">    def __init__(self, in_channels, num_classes):</span><br><span class="line">        super(InceptionAux, self).__init__()</span><br><span class="line">        self.averagePool = nn.AvgPool2d(kernel_size=5, stride=3)</span><br><span class="line">        self.conv = BasicConv2d(in_channels, 128, kernel_size=1)  # output[batch, 128, 4, 4]</span><br><span class="line"></span><br><span class="line">        self.fc1 = nn.Linear(2048, 1024)  # 2048是展平后的节点个数128*4*4</span><br><span class="line">        self.fc2 = nn.Linear(1024, num_classes)</span><br><span class="line"></span><br><span class="line">    def forward(self, x):</span><br><span class="line">        # aux1: N x 512 x 14 x 14, aux2: N x 528 x 14 x 14 输入特征矩阵的维度</span><br><span class="line">        x = self.averagePool(x)</span><br><span class="line">        # aux1: N x 512 x 4 x 4, aux2: N x 528 x 4 x 4</span><br><span class="line">        x = self.conv(x)</span><br><span class="line">        # N x 128 x 4 x 4</span><br><span class="line">        x = torch.flatten(x, 1)</span><br><span class="line">        x = F.dropout(x, 0.5, training=self.training)  # 当我们实例化一个模型model后，可以通过model.train()和model.eval()来控制模型的状态，</span><br><span class="line">        # 在model.train()模式下self.training=True，在model.eval()模式下self.training=False</span><br><span class="line">        # N x 2048</span><br><span class="line">        x = F.relu(self.fc1(x), inplace=True)</span><br><span class="line">        x = F.dropout(x, 0.5, training=self.training)</span><br><span class="line">        # N x 1024</span><br><span class="line">        x = self.fc2(x)</span><br><span class="line">        # N x num_classes</span><br><span class="line">        return x</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">class BasicConv2d(nn.Module):  # 卷积模板文件</span><br><span class="line">    def __init__(self, in_channels, out_channels, **kwargs):</span><br><span class="line">        super(BasicConv2d, self).__init__()</span><br><span class="line">        self.conv = nn.Conv2d(in_channels, out_channels, **kwargs)</span><br><span class="line">        self.relu = nn.ReLU(inplace=True)</span><br><span class="line"></span><br><span class="line">    def forward(self, x):  # 正向传播过程</span><br><span class="line">        x = self.conv(x)</span><br><span class="line">        x = self.relu(x)</span><br><span class="line">        return x</span><br></pre></td></tr></table></figure>

<p>训练：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br></pre></td><td class="code"><pre><span class="line">import torch</span><br><span class="line">import torch.nn as nn</span><br><span class="line">import torchvision.transforms as transforms</span><br><span class="line">from torchvision import datasets</span><br><span class="line">from torchvision.models import mobilenet_v3_large</span><br><span class="line">from torch.utils.data import DataLoader,random_split</span><br><span class="line">from PIL import Image</span><br><span class="line">import numpy as np</span><br><span class="line"># 加载 MobileNet V3 Large 模型</span><br><span class="line">model = mobilenet_v3_large(pretrained=True)</span><br><span class="line"># 定义数据预处理</span><br><span class="line">train_transform = transforms.Compose([</span><br><span class="line">    transforms.Resize((224, 224)),</span><br><span class="line">    transforms.RandomHorizontalFlip(),</span><br><span class="line">    transforms.ToTensor(),</span><br><span class="line">    transforms.Normalize([0.485, 0.456, 0.406],</span><br><span class="line">                         [0.229, 0.224, 0.225])</span><br><span class="line">])</span><br><span class="line"></span><br><span class="line">val_transform = transforms.Compose([</span><br><span class="line">    transforms.Resize((224, 224)),</span><br><span class="line">    transforms.ToTensor(),</span><br><span class="line">    transforms.Normalize([0.485, 0.456, 0.406],</span><br><span class="line">                         [0.229, 0.224, 0.225])</span><br><span class="line">])</span><br><span class="line">data_dir=r&quot;D:\华清补习文件\code\每日笔记\mobilenet\flower_photos&quot;</span><br><span class="line">full_dataset = datasets.ImageFolder(data_dir)</span><br><span class="line"></span><br><span class="line"># 划分训练集和验证集</span><br><span class="line">train_size = int(0.8 * len(full_dataset))</span><br><span class="line">val_size = len(full_dataset) - train_size</span><br><span class="line">train_dataset, val_dataset = random_split(full_dataset, [train_size, val_size])</span><br><span class="line"></span><br><span class="line"># 应用 transform</span><br><span class="line">train_dataset.dataset.transform = train_transform</span><br><span class="line">val_dataset.dataset.transform = val_transform</span><br><span class="line"></span><br><span class="line">train_loader =DataLoader(train_dataset, batch_size=32, shuffle=True)</span><br><span class="line">val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)</span><br><span class="line"></span><br><span class="line">device = torch.device(&quot;cuda:0&quot; if torch.cuda.is_available() else &quot;cpu&quot;)</span><br><span class="line">model = model.to(device)</span><br><span class="line"></span><br><span class="line">criterion = torch.nn.CrossEntropyLoss()</span><br><span class="line">optimizer = torch.optim.Adam(model.parameters(), lr=0.001)</span><br><span class="line"># 训练模型</span><br><span class="line"># 训练循环</span><br><span class="line">for epoch in range(10):</span><br><span class="line">    # ---------- 训练 ----------</span><br><span class="line">    model.train()</span><br><span class="line">    running_loss = 0.0</span><br><span class="line">    for inputs, labels in train_loader:</span><br><span class="line">        inputs, labels = inputs.to(device), labels.to(device)</span><br><span class="line"></span><br><span class="line">        optimizer.zero_grad()</span><br><span class="line">        outputs = model(inputs)</span><br><span class="line">        loss = criterion(outputs, labels)</span><br><span class="line">        loss.backward()</span><br><span class="line">        optimizer.step()</span><br><span class="line"></span><br><span class="line">        running_loss += loss.item()</span><br><span class="line"></span><br><span class="line">    # ---------- 验证 ----------</span><br><span class="line">    model.eval()</span><br><span class="line">    correct = 0</span><br><span class="line">    total = 0</span><br><span class="line">    with torch.no_grad():</span><br><span class="line">        for inputs, labels in val_loader:</span><br><span class="line">            inputs, labels = inputs.to(device), labels.to(device)</span><br><span class="line">            outputs = model(inputs)</span><br><span class="line">            _, preds = torch.max(outputs, 1)</span><br><span class="line">            correct += (preds == labels).sum().item()</span><br><span class="line">            total += labels.size(0)</span><br><span class="line"></span><br><span class="line">    val_acc = correct / total</span><br><span class="line">    print(f&quot;Epoch &#123;epoch+1&#125;  Loss: &#123;running_loss:.4f&#125;  Val Acc: &#123;val_acc:.4f&#125;&quot;)</span><br><span class="line">torch.save(model.state_dict(), r&#x27;D:\华清补习文件\code\每日笔记\model\Mobile_flower.pth&#x27;)</span><br></pre></td></tr></table></figure>

<p>测试：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br></pre></td><td class="code"><pre><span class="line">import os</span><br><span class="line">import json</span><br><span class="line">import torch</span><br><span class="line">from PIL import Image</span><br><span class="line">from torchvision import transforms</span><br><span class="line">import matplotlib.pyplot as plt</span><br><span class="line">from model import GoogLeNet</span><br><span class="line">import os</span><br><span class="line"></span><br><span class="line">os.environ[&quot;KMP_DUPLICATE_LIB_OK&quot;] = &quot;TRUE&quot;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def main():</span><br><span class="line">    device = torch.device(&quot;cuda:0&quot; if torch.cuda.is_available() else &quot;cpu&quot;)</span><br><span class="line"></span><br><span class="line">    data_transform = transforms.Compose(  # 依然是对数据先进行预处理</span><br><span class="line">        [transforms.Resize((224, 224)),</span><br><span class="line">         transforms.ToTensor(),</span><br><span class="line">         transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])</span><br><span class="line"></span><br><span class="line">    # load image</span><br><span class="line">    img_path = r&quot;D:\华清补习文件\code\每日笔记\goole.act\flower_photos\daisy\5794835_d15905c7c8_n.jpg&quot;</span><br><span class="line">    assert os.path.exists(img_path), &quot;file: &#x27;&#123;&#125;&#x27; dose not exist.&quot;.format(img_path)</span><br><span class="line">    img = Image.open(img_path)  # 直接使用PIL库载入一张图像</span><br><span class="line"></span><br><span class="line">    plt.imshow(img)  # 简单展示一下这张图片</span><br><span class="line">    # [N, C, H, W]</span><br><span class="line">    img = data_transform(img)  # 对图片进行预处理</span><br><span class="line">    # expand batch dimension</span><br><span class="line">    img = torch.unsqueeze(img, dim=0)  # 扩充一个维度，添加一个batch维度</span><br><span class="line"></span><br><span class="line">    class_indict=&#123;&quot;0&quot;: &quot;daisies&quot;, &quot;1&quot;: &quot;dandelion&quot;, &quot;2&quot;: &quot;roses&quot;, &quot;3&quot;: &quot;sunflowers&quot;, &quot;4&quot;: &quot;tulips&quot;&#125;</span><br><span class="line"></span><br><span class="line">    # create model</span><br><span class="line">    model = GoogLeNet(num_classes=5).to(device)  # 初始化我们的网络</span><br><span class="line"></span><br><span class="line">    # load model weights</span><br><span class="line">    weights_path = r&quot;D:\华清补习文件\code\每日笔记\model\googlenet_flower.pth&quot;</span><br><span class="line">    assert os.path.exists(weights_path), &quot;file: &#x27;&#123;&#125;&#x27; dose not exist.&quot;.format(weights_path)</span><br><span class="line">    model.load_state_dict(torch.load(weights_path))  # 载入我们的网络模型</span><br><span class="line"></span><br><span class="line">    model.eval()  # 进入eval模式，没有dropout的那个</span><br><span class="line">    with torch.no_grad():  # 不跟踪变量的损失梯度</span><br><span class="line">        # predict class</span><br><span class="line">        output = torch.squeeze(model(img.to(device))).cpu()  # 将数据通过model进行正向传播得到输出</span><br><span class="line">        # squeeze将输出进行压缩，把第一个维度的batch压缩掉了</span><br><span class="line">        predict = torch.softmax(output, dim=0)  # softmax得到概率分布</span><br><span class="line">        predict_cla = torch.argmax(predict).numpy()  # 概率最大处所对应的索引值</span><br><span class="line"></span><br><span class="line">    print_res = &quot;class: &#123;&#125;   prob: &#123;:.3&#125;&quot;.format(class_indict[str(predict_cla)],</span><br><span class="line">                                                 predict[predict_cla].numpy())</span><br><span class="line">    # 打印预测名称，已经对应类别的概率</span><br><span class="line">    plt.title(print_res)</span><br><span class="line">    for i in range(len(predict)):</span><br><span class="line">        print(&quot;class: &#123;:10&#125;   prob: &#123;:.3&#125;&quot;.format(class_indict[str(i)],</span><br><span class="line">                                                  predict[i].numpy()))</span><br><span class="line">    plt.show()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">if __name__ == &#x27;__main__&#x27;:</span><br><span class="line">    main()</span><br></pre></td></tr></table></figure>



<h4 id="1-6-3Resnet"><a href="#1-6-3Resnet" class="headerlink" title="1.6.3Resnet"></a>1.6.3Resnet</h4><p>建立模型：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">import torchvision.models as models</span><br><span class="line">import torch</span><br><span class="line">model = models.resnet18(pretrained=True)</span><br><span class="line">num_classes = 5  # 5种花</span><br><span class="line">model.fc = torch.nn.Linear(model.fc.in_features, num_classes)</span><br></pre></td></tr></table></figure>

<p>训练模型：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br></pre></td><td class="code"><pre><span class="line">import torch</span><br><span class="line">from torchvision import datasets</span><br><span class="line">import torchvision.transforms as transforms</span><br><span class="line">from torch.utils.data import DataLoader</span><br><span class="line">import random</span><br><span class="line">from PIL import Image</span><br><span class="line">import sys  # 新增：导入sys模块</span><br><span class="line">import torchvision.models as models</span><br><span class="line">import torch</span><br><span class="line">model = models.resnet18(pretrained=True)</span><br><span class="line">num_classes = 5  # 5种花</span><br><span class="line">model.fc = torch.nn.Linear(model.fc.in_features, num_classes)</span><br><span class="line">data_dir = r&#x27;D:\华清补习文件\code\每日笔记\reNet_act\flower_photos&#x27;</span><br><span class="line"></span><br><span class="line">train_transform = transforms.Compose([</span><br><span class="line">    transforms.Resize((224, 224)),</span><br><span class="line">    transforms.RandomHorizontalFlip(),</span><br><span class="line">    transforms.ToTensor(),</span><br><span class="line">    transforms.Normalize([0.485, 0.456, 0.406],</span><br><span class="line">                         [0.229, 0.224, 0.225])</span><br><span class="line">])</span><br><span class="line"></span><br><span class="line">val_transform = transforms.Compose([</span><br><span class="line">    transforms.Resize((224, 224)),</span><br><span class="line">    transforms.ToTensor(),</span><br><span class="line">    transforms.Normalize([0.485, 0.456, 0.406],</span><br><span class="line">                         [0.229, 0.224, 0.225])</span><br><span class="line">])</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">full_dataset = datasets.ImageFolder(data_dir)</span><br><span class="line"></span><br><span class="line"># 划分训练集和验证集</span><br><span class="line">train_size = int(0.8 * len(full_dataset))</span><br><span class="line">val_size = len(full_dataset) - train_size</span><br><span class="line">train_dataset, val_dataset = torch.utils.data.random_split(full_dataset, [train_size, val_size])</span><br><span class="line"></span><br><span class="line"># 应用 transform</span><br><span class="line">train_dataset.dataset.transform = train_transform</span><br><span class="line">val_dataset.dataset.transform = val_transform</span><br><span class="line"></span><br><span class="line">train_loader =DataLoader(train_dataset, batch_size=32, shuffle=True)</span><br><span class="line">val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)</span><br><span class="line"></span><br><span class="line">device = torch.device(&quot;cuda:0&quot; if torch.cuda.is_available() else &quot;cpu&quot;)</span><br><span class="line">model = model.to(device)</span><br><span class="line"></span><br><span class="line">criterion = torch.nn.CrossEntropyLoss()</span><br><span class="line">optimizer = torch.optim.Adam(model.parameters(), lr=0.001)</span><br><span class="line"></span><br><span class="line"># 训练循环</span><br><span class="line">for epoch in range(10):</span><br><span class="line">    # ---------- 训练 ----------</span><br><span class="line">    model.train()</span><br><span class="line">    running_loss = 0.0</span><br><span class="line">    for inputs, labels in train_loader:</span><br><span class="line">        inputs, labels = inputs.to(device), labels.to(device)</span><br><span class="line"></span><br><span class="line">        optimizer.zero_grad()</span><br><span class="line">        outputs = model(inputs)</span><br><span class="line">        loss = criterion(outputs, labels)</span><br><span class="line">        loss.backward()</span><br><span class="line">        optimizer.step()</span><br><span class="line"></span><br><span class="line">        running_loss += loss.item()</span><br><span class="line"></span><br><span class="line">    # ---------- 验证 ----------</span><br><span class="line">    model.eval()</span><br><span class="line">    correct = 0</span><br><span class="line">    total = 0</span><br><span class="line">    with torch.no_grad():</span><br><span class="line">        for inputs, labels in val_loader:</span><br><span class="line">            inputs, labels = inputs.to(device), labels.to(device)</span><br><span class="line">            outputs = model(inputs)</span><br><span class="line">            _, preds = torch.max(outputs, 1)</span><br><span class="line">            correct += (preds == labels).sum().item()</span><br><span class="line">            total += labels.size(0)</span><br><span class="line"></span><br><span class="line">    val_acc = correct / total</span><br><span class="line">    print(f&quot;Epoch &#123;epoch+1&#125;  Loss: &#123;running_loss:.4f&#125;  Val Acc: &#123;val_acc:.4f&#125;&quot;)</span><br><span class="line">torch.save(model.state_dict(), r&#x27;D:\华清补习文件\code\每日笔记\model\resnet_flower.pth&#x27;)</span><br></pre></td></tr></table></figure>

<p> 测试：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br></pre></td><td class="code"><pre><span class="line">import torch</span><br><span class="line">import torchvision.transforms as transforms</span><br><span class="line">from PIL import Image</span><br><span class="line">from model import create_vgg_model</span><br><span class="line">import torchvision</span><br><span class="line">import random  # 新增：用于随机选择图片</span><br><span class="line"></span><br><span class="line"># ---------------------- 动态获取类别名称和数据集信息 ----------------------</span><br><span class="line">data_root = r&#x27;D:\华清补习文件\code\每日笔记\vgg\flower_photos&#x27;</span><br><span class="line">full_dataset = torchvision.datasets.ImageFolder(root=data_root)</span><br><span class="line">class_names = full_dataset.classes  # 自动获取类别名</span><br><span class="line">image_paths = [item[0] for item in full_dataset.imgs]  # 所有图片路径</span><br><span class="line">labels = [item[1] for item in full_dataset.imgs]  # 所有图片标签</span><br><span class="line"></span><br><span class="line"># 保持与训练时相同的数据集划分（8:2比例）</span><br><span class="line">train_size = int(0.8 * len(image_paths))</span><br><span class="line">indices = list(range(len(image_paths)))</span><br><span class="line">random.shuffle(indices)  # 随机打乱索引</span><br><span class="line">_, test_indices = indices[:train_size], indices[train_size:]  # 只需要测试集索引</span><br><span class="line"></span><br><span class="line"># 测试集图片路径和对应标签</span><br><span class="line">test_image_paths = [image_paths[i] for i in test_indices]</span><br><span class="line">test_labels = [labels[i] for i in test_indices]</span><br><span class="line"></span><br><span class="line"># ---------------------- 图像预处理（与验证集一致） ----------------------</span><br><span class="line">transform = transforms.Compose([</span><br><span class="line">    transforms.Resize(256),</span><br><span class="line">    transforms.CenterCrop(224),</span><br><span class="line">    transforms.ToTensor(),</span><br><span class="line">    transforms.Normalize(</span><br><span class="line">        mean=[0.485, 0.456, 0.406],</span><br><span class="line">        std=[0.229, 0.224, 0.225]</span><br><span class="line">    )</span><br><span class="line">])</span><br><span class="line"></span><br><span class="line"># ---------------------- 加载模型 ----------------------</span><br><span class="line">num_classes = len(class_names)</span><br><span class="line">model = create_vgg_model(num_classes=num_classes)</span><br><span class="line">model.load_state_dict(torch.load(&#x27;best_model.pth&#x27;))  # 加载训练好的权重</span><br><span class="line">model.eval()  # 切换到评估模式</span><br><span class="line">device = torch.device(&quot;cuda&quot; if torch.cuda.is_available() else &quot;cpu&quot;)</span><br><span class="line">model.to(device)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># ---------------------- 预测函数 ----------------------</span><br><span class="line">def predict_image(image_path):</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    预测单张图片的类别和概率</span><br><span class="line">    :param image_path: 图片路径</span><br><span class="line">    :return: (类别名称, 预测概率)</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    image = Image.open(image_path).convert(&#x27;RGB&#x27;)  # 打开并转为RGB</span><br><span class="line">    image = transform(image).unsqueeze(0).to(device)  # 预处理并添加batch维度</span><br><span class="line"></span><br><span class="line">    with torch.no_grad():</span><br><span class="line">        outputs = model(image)</span><br><span class="line">        _, preds = torch.max(outputs, 1)  # 获取预测类别索引</span><br><span class="line">        prob = torch.softmax(outputs, dim=1)[0][preds].item()  # 计算预测概率</span><br><span class="line"></span><br><span class="line">    return class_names[preds.item()], prob</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># ---------------------- 测试示例 ----------------------</span><br><span class="line">if __name__ == &#x27;__main__&#x27;:</span><br><span class="line">    # 从测试集中随机选择一张图片</span><br><span class="line">    random_index = random.randint(0, len(test_image_paths) - 1)</span><br><span class="line">    test_image = test_image_paths[random_index]</span><br><span class="line">    true_label = class_names[test_labels[random_index]]</span><br><span class="line"></span><br><span class="line">    # 进行预测</span><br><span class="line">    predicted_class, prob = predict_image(test_image)</span><br><span class="line"></span><br><span class="line">    # 输出结果</span><br><span class="line">    print(f&#x27;测试图片路径: &#123;test_image&#125;&#x27;)</span><br><span class="line">    print(f&#x27;真实类别: &#123;true_label&#125;&#x27;)</span><br><span class="line">    print(f&#x27;预测类别: &#123;predicted_class&#125;&#x27;)</span><br><span class="line">    print(f&#x27;预测概率: &#123;prob:.4f&#125;&#x27;)</span><br><span class="line">    print(f&#x27;预测&#123;&quot;正确&quot; if predicted_class == true_label else &quot;错误&quot;&#125;&#x27;)</span><br><span class="line"></span><br></pre></td></tr></table></figure>



<h4 id="1-6-4VGGNet"><a href="#1-6-4VGGNet" class="headerlink" title="1.6.4VGGNet"></a>1.6.4VGGNet</h4><p>搭建模型：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line">import torch</span><br><span class="line">import torch.nn as nn</span><br><span class="line">import torchvision.models as models</span><br><span class="line">from torchvision.models import VGG16_Weights  # 新增：导入权重类</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def create_vgg_model(num_classes, use_pretrained=True, freeze_features=True):</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    创建VGG16模型，修改最后一层分类器</span><br><span class="line">    :param num_classes: 分类类别数（如花卉数据集为5类）</span><br><span class="line">    :param use_pretrained: 是否加载预训练权重（默认True，使用ImageNet预训练参数）</span><br><span class="line">    :param freeze_features: 是否冻结特征提取层（默认True，仅训练分类器）</span><br><span class="line">    :return: 自定义VGG模型</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    # 加载预训练VGG16，使用新的weights参数替代pretrained</span><br><span class="line">    if use_pretrained:</span><br><span class="line">        # 使用最新的预训练权重</span><br><span class="line">        model = models.vgg16(weights=VGG16_Weights.DEFAULT)</span><br><span class="line">    else:</span><br><span class="line">        # 不使用预训练权重</span><br><span class="line">        model = models.vgg16(weights=None)</span><br><span class="line"></span><br><span class="line">    # 冻结特征提取层（可选，加速训练）</span><br><span class="line">    if freeze_features:</span><br><span class="line">        for param in model.features.parameters():</span><br><span class="line">            param.requires_grad = False</span><br><span class="line"></span><br><span class="line">    # 修改分类器最后一层（适配目标类别数）</span><br><span class="line">    num_ftrs = model.classifier[6].in_features  # 提取全连接层输入维度</span><br><span class="line">    model.classifier[6] = nn.Linear(num_ftrs, num_classes)  # 替换为目标类别数</span><br><span class="line"></span><br><span class="line">    return model</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>训练模型</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br></pre></td><td class="code"><pre><span class="line">import torch</span><br><span class="line">import torch.utils.data as data</span><br><span class="line">import torchvision</span><br><span class="line">import torchvision.transforms as transforms</span><br><span class="line">import random</span><br><span class="line">from PIL import Image</span><br><span class="line">from model import create_vgg_model</span><br><span class="line">import sys  # 新增：导入sys模块</span><br><span class="line"></span><br><span class="line"># ---------------------- 数据预处理 ----------------------</span><br><span class="line">train_transform = transforms.Compose([</span><br><span class="line">    transforms.RandomResizedCrop(224),  # 随机裁剪为224x224（VGG输入尺寸）</span><br><span class="line">    transforms.RandomHorizontalFlip(),  # 随机水平翻转（数据增强）</span><br><span class="line">    transforms.ToTensor(),  # 转为Tensor</span><br><span class="line">    transforms.Normalize(  # 归一化（ImageNet均值/标准差）</span><br><span class="line">        mean=[0.485, 0.456, 0.406],</span><br><span class="line">        std=[0.229, 0.224, 0.225]</span><br><span class="line">    )</span><br><span class="line">])</span><br><span class="line"></span><br><span class="line">val_transform = transforms.Compose([</span><br><span class="line">    transforms.Resize(256),  # resize到256x256</span><br><span class="line">    transforms.CenterCrop(224),  # 中心裁剪为224x224</span><br><span class="line">    transforms.ToTensor(),  # 转为Tensor</span><br><span class="line">    transforms.Normalize(  # 同训练集的归一化参数</span><br><span class="line">        mean=[0.485, 0.456, 0.406],</span><br><span class="line">        std=[0.229, 0.224, 0.225]</span><br><span class="line">    )</span><br><span class="line">])</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># ---------------------- 自定义数据集 ----------------------</span><br><span class="line">class FlowerDataset(data.Dataset):</span><br><span class="line">    def __init__(self, image_paths, labels, transform=None):</span><br><span class="line">        self.image_paths = image_paths</span><br><span class="line">        self.labels = labels</span><br><span class="line">        self.transform = transform</span><br><span class="line"></span><br><span class="line">    def __len__(self):</span><br><span class="line">        return len(self.image_paths)</span><br><span class="line"></span><br><span class="line">    def __getitem__(self, idx):</span><br><span class="line">        image = Image.open(self.image_paths[idx]).convert(&#x27;RGB&#x27;)  # 确保RGB格式</span><br><span class="line">        label = self.labels[idx]</span><br><span class="line">        if self.transform:</span><br><span class="line">            image = self.transform(image)</span><br><span class="line">        return image, label</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># ---------------------- 主程序逻辑（新增保护机制） ----------------------</span><br><span class="line">def main():</span><br><span class="line">    # 加载并划分数据集</span><br><span class="line">    data_root = r&#x27;D:\华清补习文件\code\每日笔记\vgg\flower_photos&#x27;</span><br><span class="line">    full_dataset = torchvision.datasets.ImageFolder(root=data_root)</span><br><span class="line">    image_paths = [item[0] for item in full_dataset.imgs]  # 所有图片路径</span><br><span class="line">    labels = [item[1] for item in full_dataset.imgs]  # 所有图片标签</span><br><span class="line">    num_classes = len(full_dataset.classes)  # 类别数</span><br><span class="line"></span><br><span class="line">    # 划分训练集和验证集（8:2比例）</span><br><span class="line">    train_size = int(0.8 * len(image_paths))</span><br><span class="line">    indices = list(range(len(image_paths)))</span><br><span class="line">    random.shuffle(indices)  # 随机打乱索引</span><br><span class="line">    train_indices, val_indices = indices[:train_size], indices[train_size:]</span><br><span class="line"></span><br><span class="line">    # 创建训练集和验证集</span><br><span class="line">    train_dataset = FlowerDataset(</span><br><span class="line">        [image_paths[i] for i in train_indices],</span><br><span class="line">        [labels[i] for i in train_indices],</span><br><span class="line">        transform=train_transform</span><br><span class="line">    )</span><br><span class="line">    val_dataset = FlowerDataset(</span><br><span class="line">        [image_paths[i] for i in val_indices],</span><br><span class="line">        [labels[i] for i in val_indices],</span><br><span class="line">        transform=val_transform</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    # 创建数据加载器 - 注意：Windows系统建议将num_workers设为0</span><br><span class="line">    batch_size = 32</span><br><span class="line">    # 检测操作系统，如果是Windows则将num_workers设为0</span><br><span class="line">    num_workers = 0 if sys.platform.startswith(&#x27;win&#x27;) else 4</span><br><span class="line">    train_loader = data.DataLoader(</span><br><span class="line">        train_dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers</span><br><span class="line">    )</span><br><span class="line">    val_loader = data.DataLoader(</span><br><span class="line">        val_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    # 模型初始化与训练</span><br><span class="line">    model = create_vgg_model(num_classes=num_classes)</span><br><span class="line">    device = torch.device(&quot;cuda&quot; if torch.cuda.is_available() else &quot;cpu&quot;)</span><br><span class="line">    model.to(device)</span><br><span class="line"></span><br><span class="line">    # 定义损失函数和优化器</span><br><span class="line">    criterion = torch.nn.CrossEntropyLoss()</span><br><span class="line">    optimizer = torch.optim.Adam(model.classifier.parameters(), lr=0.001)</span><br><span class="line"></span><br><span class="line">    # 训练参数</span><br><span class="line">    num_epochs = 10</span><br><span class="line">    best_val_acc = 0.0  # 记录最佳验证集准确率</span><br><span class="line"></span><br><span class="line">    for epoch in range(num_epochs):</span><br><span class="line">        # 训练阶段</span><br><span class="line">        model.train()</span><br><span class="line">        train_loss = 0.0</span><br><span class="line">        train_correct = 0</span><br><span class="line">        for inputs, labels in train_loader:</span><br><span class="line">            inputs, labels = inputs.to(device), labels.to(device)</span><br><span class="line">            optimizer.zero_grad()  # 清空梯度</span><br><span class="line">            outputs = model(inputs)  # 前向传播</span><br><span class="line">            loss = criterion(outputs, labels)  # 计算损失</span><br><span class="line">            loss.backward()  # 反向传播</span><br><span class="line">            optimizer.step()  # 更新参数</span><br><span class="line"></span><br><span class="line">            # 统计损失和准确率</span><br><span class="line">            train_loss += loss.item() * inputs.size(0)</span><br><span class="line">            _, preds = torch.max(outputs, 1)  # 预测类别</span><br><span class="line">            train_correct += torch.sum(preds == labels.data)</span><br><span class="line"></span><br><span class="line">        # 计算训练集指标</span><br><span class="line">        train_epoch_loss = train_loss / len(train_dataset)</span><br><span class="line">        train_epoch_acc = train_correct.double() / len(train_dataset)</span><br><span class="line"></span><br><span class="line">        # 验证阶段</span><br><span class="line">        model.eval()</span><br><span class="line">        val_loss = 0.0</span><br><span class="line">        val_correct = 0</span><br><span class="line">        with torch.no_grad():  # 关闭梯度计算，加速推理</span><br><span class="line">            for inputs, labels in val_loader:</span><br><span class="line">                inputs, labels = inputs.to(device), labels.to(device)</span><br><span class="line">                outputs = model(inputs)</span><br><span class="line">                loss = criterion(outputs, labels)</span><br><span class="line"></span><br><span class="line">                val_loss += loss.item() * inputs.size(0)</span><br><span class="line">                _, preds = torch.max(outputs, 1)</span><br><span class="line">                val_correct += torch.sum(preds == labels.data)</span><br><span class="line"></span><br><span class="line">        # 计算验证集指标</span><br><span class="line">        val_epoch_loss = val_loss / len(val_dataset)</span><br><span class="line">        val_epoch_acc = val_correct.double() / len(val_dataset)</span><br><span class="line"></span><br><span class="line">        # 打印训练日志</span><br><span class="line">        print(f&#x27;Epoch &#123;epoch + 1&#125;/&#123;num_epochs&#125;&#x27;)</span><br><span class="line">        print(f&#x27;Train Loss: &#123;train_epoch_loss:.4f&#125; | Acc: &#123;train_epoch_acc:.4f&#125;&#x27;)</span><br><span class="line">        print(f&#x27;Val Loss: &#123;val_epoch_loss:.4f&#125; | Acc: &#123;val_epoch_acc:.4f&#125;&#x27;)</span><br><span class="line"></span><br><span class="line">        # 保存最佳模型（根据验证集准确率）</span><br><span class="line">        if val_epoch_acc &gt; best_val_acc:</span><br><span class="line">            best_val_acc = val_epoch_acc</span><br><span class="line">            torch.save(model.state_dict(), r&#x27;D:\华清补习文件\code\每日笔记\model\vgg_model.pth&#x27;)</span><br><span class="line"></span><br><span class="line">    print(f&#x27;Training Complete! Best Validation Accuracy: &#123;best_val_acc:.4f&#125;&#x27;)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 解决Windows多进程问题的关键代码</span><br><span class="line">if __name__ == &#x27;__main__&#x27;:</span><br><span class="line">    # 在Windows系统上需要添加freeze_support()</span><br><span class="line">    if sys.platform.startswith(&#x27;win&#x27;):</span><br><span class="line">        torch.multiprocessing.freeze_support()</span><br><span class="line">    main()</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>测试：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br></pre></td><td class="code"><pre><span class="line">import torch</span><br><span class="line">import torchvision.transforms as transforms</span><br><span class="line">from PIL import Image</span><br><span class="line">from model import create_vgg_model</span><br><span class="line">import torchvision</span><br><span class="line">import random  # 新增：用于随机选择图片</span><br><span class="line"></span><br><span class="line"># ---------------------- 动态获取类别名称和数据集信息 ----------------------</span><br><span class="line">data_root = r&#x27;D:\华清补习文件\code\每日笔记\vgg\flower_photos&#x27;</span><br><span class="line">full_dataset = torchvision.datasets.ImageFolder(root=data_root)</span><br><span class="line">class_names = full_dataset.classes  # 自动获取类别名</span><br><span class="line">image_paths = [item[0] for item in full_dataset.imgs]  # 所有图片路径</span><br><span class="line">labels = [item[1] for item in full_dataset.imgs]  # 所有图片标签</span><br><span class="line"></span><br><span class="line"># 保持与训练时相同的数据集划分（8:2比例）</span><br><span class="line">train_size = int(0.8 * len(image_paths))</span><br><span class="line">indices = list(range(len(image_paths)))</span><br><span class="line">random.shuffle(indices)  # 随机打乱索引</span><br><span class="line">_, test_indices = indices[:train_size], indices[train_size:]  # 只需要测试集索引</span><br><span class="line"></span><br><span class="line"># 测试集图片路径和对应标签</span><br><span class="line">test_image_paths = [image_paths[i] for i in test_indices]</span><br><span class="line">test_labels = [labels[i] for i in test_indices]</span><br><span class="line"></span><br><span class="line"># ---------------------- 图像预处理（与验证集一致） ----------------------</span><br><span class="line">transform = transforms.Compose([</span><br><span class="line">    transforms.Resize(256),</span><br><span class="line">    transforms.CenterCrop(224),</span><br><span class="line">    transforms.ToTensor(),</span><br><span class="line">    transforms.Normalize(</span><br><span class="line">        mean=[0.485, 0.456, 0.406],</span><br><span class="line">        std=[0.229, 0.224, 0.225]</span><br><span class="line">    )</span><br><span class="line">])</span><br><span class="line"></span><br><span class="line"># ---------------------- 加载模型 ----------------------</span><br><span class="line">num_classes = len(class_names)</span><br><span class="line">model = create_vgg_model(num_classes=num_classes)</span><br><span class="line">model.load_state_dict(torch.load(&#x27;best_model.pth&#x27;))  # 加载训练好的权重</span><br><span class="line">model.eval()  # 切换到评估模式</span><br><span class="line">device = torch.device(&quot;cuda&quot; if torch.cuda.is_available() else &quot;cpu&quot;)</span><br><span class="line">model.to(device)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># ---------------------- 预测函数 ----------------------</span><br><span class="line">def predict_image(image_path):</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    预测单张图片的类别和概率</span><br><span class="line">    :param image_path: 图片路径</span><br><span class="line">    :return: (类别名称, 预测概率)</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    image = Image.open(image_path).convert(&#x27;RGB&#x27;)  # 打开并转为RGB</span><br><span class="line">    image = transform(image).unsqueeze(0).to(device)  # 预处理并添加batch维度</span><br><span class="line"></span><br><span class="line">    with torch.no_grad():</span><br><span class="line">        outputs = model(image)</span><br><span class="line">        _, preds = torch.max(outputs, 1)  # 获取预测类别索引</span><br><span class="line">        prob = torch.softmax(outputs, dim=1)[0][preds].item()  # 计算预测概率</span><br><span class="line"></span><br><span class="line">    return class_names[preds.item()], prob</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># ---------------------- 测试示例 ----------------------</span><br><span class="line">if __name__ == &#x27;__main__&#x27;:</span><br><span class="line">    # 从测试集中随机选择一张图片</span><br><span class="line">    random_index = random.randint(0, len(test_image_paths) - 1)</span><br><span class="line">    test_image = test_image_paths[random_index]</span><br><span class="line">    true_label = class_names[test_labels[random_index]]</span><br><span class="line"></span><br><span class="line">    # 进行预测</span><br><span class="line">    predicted_class, prob = predict_image(test_image)</span><br><span class="line"></span><br><span class="line">    # 输出结果</span><br><span class="line">    print(f&#x27;测试图片路径: &#123;test_image&#125;&#x27;)</span><br><span class="line">    print(f&#x27;真实类别: &#123;true_label&#125;&#x27;)</span><br><span class="line">    print(f&#x27;预测类别: &#123;predicted_class&#125;&#x27;)</span><br><span class="line">    print(f&#x27;预测概率: &#123;prob:.4f&#125;&#x27;)</span><br><span class="line">    print(f&#x27;预测&#123;&quot;正确&quot; if predicted_class == true_label else &quot;错误&quot;&#125;&#x27;)</span><br><span class="line"></span><br></pre></td></tr></table></figure>



<h4 id="1-6-5AlexNet"><a href="#1-6-5AlexNet" class="headerlink" title="1.6.5AlexNet"></a>1.6.5AlexNet</h4><p>搭建模型：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br></pre></td><td class="code"><pre><span class="line">import torch</span><br><span class="line">import torch.nn as nn</span><br><span class="line">import torch.nn.functional as F</span><br><span class="line">import torch.optim as optim</span><br><span class="line">from torch.optim.lr_scheduler import CosineAnnealingLR, ReduceLROnPlateau</span><br><span class="line"></span><br><span class="line"># 注意力模块</span><br><span class="line">class SELayer(nn.Module):</span><br><span class="line">    def __init__(self, channel, reduction=16):</span><br><span class="line">        super(SELayer, self).__init__()</span><br><span class="line">        self.avg_pool = nn.AdaptiveAvgPool2d(1)</span><br><span class="line">        self.fc = nn.Sequential(</span><br><span class="line">            nn.Linear(channel, channel // reduction, bias=False),</span><br><span class="line">            nn.ReLU(inplace=True),</span><br><span class="line">            nn.Linear(channel // reduction, channel, bias=False),</span><br><span class="line">            nn.Sigmoid()</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">    def forward(self, x):</span><br><span class="line">        b, c, _, _ = x.size()</span><br><span class="line">        y = self.avg_pool(x).view(b, c)</span><br><span class="line">        y = self.fc(y).view(b, c, 1, 1)</span><br><span class="line">        return x * y.expand_as(x)</span><br><span class="line"></span><br><span class="line">class ImprovedAlexNet(nn.Module):</span><br><span class="line">    def __init__(self, num_classes=1000, dropout_rate=0.3, init_weights=True):</span><br><span class="line">        super(ImprovedAlexNet, self).__init__()</span><br><span class="line">        </span><br><span class="line">        # 特征提取部分 - 增加残差连接和注意力机制</span><br><span class="line">        self.features = nn.Sequential(</span><br><span class="line">            # 第一层卷积 + 批标准化 + Swish激活</span><br><span class="line">            nn.Conv2d(3, 48, kernel_size=11, stride=4, padding=2, bias=False),</span><br><span class="line">            nn.BatchNorm2d(48),</span><br><span class="line">            nn.SiLU(inplace=True),</span><br><span class="line">            nn.MaxPool2d(kernel_size=3, stride=2),</span><br><span class="line">            </span><br><span class="line">            # 第二层 - 残差块</span><br><span class="line">            ResidualBlock(48, 128, kernel_size=5, padding=2),</span><br><span class="line">            nn.MaxPool2d(kernel_size=3, stride=2),</span><br><span class="line">            </span><br><span class="line">            # 第三层 - 带注意力的深度可分离卷积</span><br><span class="line">            DepthwiseSeparableConv(128, 192, kernel_size=3, padding=1),</span><br><span class="line">            SELayer(192, reduction=8),</span><br><span class="line">            nn.SiLU(inplace=True),</span><br><span class="line">            </span><br><span class="line">            # 第四层 - 带注意力的深度可分离卷积</span><br><span class="line">            DepthwiseSeparableConv(192, 192, kernel_size=3, padding=1),</span><br><span class="line">            SELayer(192, reduction=8),</span><br><span class="line">            nn.SiLU(inplace=True),</span><br><span class="line">            </span><br><span class="line">            # 第五层 - 残差块 + 池化</span><br><span class="line">            ResidualBlock(192, 128, kernel_size=3, padding=1),</span><br><span class="line">            nn.AdaptiveAvgPool2d((6, 6))</span><br><span class="line">        )</span><br><span class="line">        </span><br><span class="line">        # 分类器部分 - 增加BatchNorm和调整Dropout</span><br><span class="line">        self.classifier = nn.Sequential(</span><br><span class="line">            nn.Dropout(dropout_rate),</span><br><span class="line">            nn.Linear(128 * 6 * 6, 1024, bias=False),</span><br><span class="line">            nn.BatchNorm1d(1024),</span><br><span class="line">            nn.SiLU(inplace=True),</span><br><span class="line">            </span><br><span class="line">            nn.Dropout(dropout_rate),</span><br><span class="line">            nn.Linear(1024, 512, bias=False),</span><br><span class="line">            nn.BatchNorm1d(512),</span><br><span class="line">            nn.SiLU(inplace=True),</span><br><span class="line">            </span><br><span class="line">            nn.Linear(512, num_classes)</span><br><span class="line">        )</span><br><span class="line">        </span><br><span class="line">        if init_weights:</span><br><span class="line">            self._initialize_weights()</span><br><span class="line">    </span><br><span class="line">    def forward(self, x):</span><br><span class="line">        x = self.features(x)</span><br><span class="line">        x = torch.flatten(x, 1)</span><br><span class="line">        x = self.classifier(x)</span><br><span class="line">        return x</span><br><span class="line">    </span><br><span class="line">    def _initialize_weights(self):</span><br><span class="line">        for m in self.modules():</span><br><span class="line">            if isinstance(m, nn.Conv2d):</span><br><span class="line">                nn.init.kaiming_normal_(m.weight, mode=&#x27;fan_in&#x27;, nonlinearity=&#x27;leaky_relu&#x27;)</span><br><span class="line">                if m.bias is not None:</span><br><span class="line">                    nn.init.constant_(m.bias, 0)</span><br><span class="line">            elif isinstance(m, nn.BatchNorm2d) or isinstance(m, nn.BatchNorm1d):</span><br><span class="line">                nn.init.constant_(m.weight, 1)</span><br><span class="line">                nn.init.constant_(m.bias, 0)</span><br><span class="line">            elif isinstance(m, nn.Linear):</span><br><span class="line">                nn.init.normal_(m.weight, 0, 0.01)</span><br><span class="line">                if m.bias is not None:</span><br><span class="line">                    nn.init.constant_(m.bias, 0)</span><br><span class="line"></span><br><span class="line"># 残差块</span><br><span class="line">class ResidualBlock(nn.Module):</span><br><span class="line">    def __init__(self, in_channels, out_channels, kernel_size, padding):</span><br><span class="line">        super(ResidualBlock, self).__init__()</span><br><span class="line">        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size, padding=padding, bias=False)</span><br><span class="line">        self.bn1 = nn.BatchNorm2d(out_channels)</span><br><span class="line">        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size, padding=padding, bias=False)</span><br><span class="line">        self.bn2 = nn.BatchNorm2d(out_channels)</span><br><span class="line">        </span><br><span class="line">        # 如果输入和输出通道数不同，使用1x1卷积调整维度</span><br><span class="line">        self.shortcut = nn.Sequential()</span><br><span class="line">        if in_channels != out_channels:</span><br><span class="line">            self.shortcut = nn.Sequential(</span><br><span class="line">                nn.Conv2d(in_channels, out_channels, kernel_size=1, bias=False),</span><br><span class="line">                nn.BatchNorm2d(out_channels)</span><br><span class="line">            )</span><br><span class="line"></span><br><span class="line">    def forward(self, x):</span><br><span class="line">        out = F.silu(self.bn1(self.conv1(x)))</span><br><span class="line">        out = self.bn2(self.conv2(out))</span><br><span class="line">        out += self.shortcut(x)</span><br><span class="line">        out = F.silu(out)</span><br><span class="line">        return out</span><br><span class="line"></span><br><span class="line"># 深度可分离卷积</span><br><span class="line">class DepthwiseSeparableConv(nn.Module):</span><br><span class="line">    def __init__(self, in_channels, out_channels, kernel_size, padding):</span><br><span class="line">        super(DepthwiseSeparableConv, self).__init__()</span><br><span class="line">        self.depthwise = nn.Conv2d(in_channels, in_channels, kernel_size, </span><br><span class="line">                                   padding=padding, groups=in_channels, bias=False)</span><br><span class="line">        self.pointwise = nn.Conv2d(in_channels, out_channels, kernel_size=1, bias=False)</span><br><span class="line">        self.bn = nn.BatchNorm2d(out_channels)</span><br><span class="line"></span><br><span class="line">    def forward(self, x):</span><br><span class="line">        x = self.depthwise(x)</span><br><span class="line">        x = self.pointwise(x)</span><br><span class="line">        x = self.bn(x)</span><br><span class="line">        return x</span><br></pre></td></tr></table></figure>

<p>训练模型：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br></pre></td><td class="code"><pre><span class="line">import os</span><br><span class="line">import sys</span><br><span class="line">import json</span><br><span class="line">import torch</span><br><span class="line">import torch.nn as nn</span><br><span class="line">from torchvision import transforms, datasets, utils</span><br><span class="line">from torch.utils.data import DataLoader,random_split</span><br><span class="line">import matplotlib.pyplot as plt</span><br><span class="line">import numpy as np</span><br><span class="line">import torch.optim as optim</span><br><span class="line">from tqdm import tqdm</span><br><span class="line">from model import ImprovedAlexNet as AlexNet</span><br><span class="line"></span><br><span class="line">class TransformedSubset(torch.utils.data.Dataset):</span><br><span class="line">    def __init__(self, subset, transform):</span><br><span class="line">        self.subset = subset</span><br><span class="line">        self.transform = transform</span><br><span class="line"></span><br><span class="line">    def __len__(self):</span><br><span class="line">        return len(self.subset)</span><br><span class="line"></span><br><span class="line">    def __getitem__(self, idx):</span><br><span class="line">        x, y = self.subset[idx]</span><br><span class="line">        if self.transform:</span><br><span class="line">            x = self.transform(x)</span><br><span class="line">        return x, y</span><br><span class="line"></span><br><span class="line">def main():</span><br><span class="line">    # 使用GPU</span><br><span class="line">    device = torch.device(&quot;cuda:0&quot; if torch.cuda.is_available() else &quot;cpu&quot;)</span><br><span class="line">    print(&quot;using &#123;&#125; device.&quot;.format(device))</span><br><span class="line">    </span><br><span class="line">    data_transform = &#123;</span><br><span class="line">        &quot;train&quot;:</span><br><span class="line">            transforms.Compose([</span><br><span class="line">                transforms.RandomResizedCrop(224),  # 随机裁剪 224*224</span><br><span class="line">                transforms.RandomHorizontalFlip(),  # 随机翻转 水平方向随机翻转进行数据增强</span><br><span class="line">                transforms.ToTensor(),  # 转化为Tensor</span><br><span class="line">                transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))</span><br><span class="line">            ]),</span><br><span class="line">        &quot;test&quot;:</span><br><span class="line">            transforms.Compose([</span><br><span class="line">                transforms.Resize((224, 224)),  # cannot 224, must (224, 224)</span><br><span class="line">                transforms.ToTensor(),</span><br><span class="line">                transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))</span><br><span class="line">            ])</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    #data_root = os.path.abspath(os.path.join(os.getcwd(),&quot;&quot;))  # get data root path</span><br><span class="line">    data_dir = r&#x27;D:\华清补习文件\code\每日笔记\ALexNet_act\flower_photos&#x27;  # get data root path</span><br><span class="line"></span><br><span class="line">    # os.getcwd()函数是获得这个文件所在的根目录，../表示返回上一层目录，../..就是返回上上层目录</span><br><span class="line">    # 图像预处理</span><br><span class="line">    transform = transforms.Compose([</span><br><span class="line">        transforms.Resize((224, 224)),</span><br><span class="line">        transforms.ToTensor(),</span><br><span class="line">    ])</span><br><span class="line"></span><br><span class="line">    # 加载整个数据集</span><br><span class="line">    full_dataset = datasets.ImageFolder(root=data_dir)</span><br><span class="line"></span><br><span class="line">    # 划分训练集和测试集（例如 80% 训练，20% 测试）</span><br><span class="line">    train_size = int(0.8 * len(full_dataset))</span><br><span class="line">    test_size = len(full_dataset) - train_size</span><br><span class="line">    train_dataset, test_dataset = random_split(full_dataset, [train_size, test_size])</span><br><span class="line">    train_dataset = TransformedSubset(train_dataset, data_transform[&#x27;train&#x27;])</span><br><span class="line">    test_dataset = TransformedSubset(test_dataset, data_transform[&#x27;test&#x27;])</span><br><span class="line">    # 使用ImageFolder来加载数据集，train表示加载训练集数据，transform就是使用之前定义的数据预处理</span><br><span class="line">    train_num = len(train_dataset)  # 训练集有多少张图片</span><br><span class="line"></span><br><span class="line">    # 字典，类别：索引&#123;&#x27;daisy&#x27;:0, &#x27;dandelion&#x27;:1, &#x27;roses&#x27;:2, &#x27;sunflower&#x27;:3, &#x27;tulips&#x27;:4&#125;</span><br><span class="line">    flower_list = full_dataset.class_to_idx  # 去获取分类名称所对应的索引</span><br><span class="line">    cla_dict = dict((val, key) for key, val in flower_list.items())</span><br><span class="line">    # 遍历flower_list这个字典，将key和value对调,也就是键值变成0，value变成daisy</span><br><span class="line">    # trainset.classes可以直接获得类别的lise（待研究</span><br><span class="line">    # write dict into json file</span><br><span class="line">    json_str = json.dumps(cla_dict, indent=4)</span><br><span class="line">    # 通过json包将我们cla_dict这个字典进行编码，编码成json格式</span><br><span class="line">    with open(&#x27;class_indices.json&#x27;,</span><br><span class="line">              &#x27;w&#x27;) as json_file:  # 保存class_indices.json文件，w是以写入的方式打开文件</span><br><span class="line">        json_file.write(json_str)  # 能够在预测时方便读取它的信息</span><br><span class="line"></span><br><span class="line">    batch_size = 32</span><br><span class="line"> </span><br><span class="line">    train_loader = torch.utils.data.DataLoader(train_dataset,</span><br><span class="line">                                               batch_size=batch_size,</span><br><span class="line">                                               shuffle=True,</span><br><span class="line">                                               num_workers=0)</span><br><span class="line">    # num_workers就代表加载数据集所使用的线程个数，win系统中不能设置为非0值，可以删去上一行直接写0</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    test_num = len(test_dataset)  # 测试集的文件个数</span><br><span class="line">    test_loader = torch.utils.data.DataLoader(test_dataset,</span><br><span class="line">                                                  batch_size=4,</span><br><span class="line">                                                  shuffle=False,</span><br><span class="line">                                                  num_workers=0)</span><br><span class="line">    # 使用DataLoader去载入验证集</span><br><span class="line">    print(&quot;using &#123;&#125; images for training, &#123;&#125; images for validation.&quot;.format(</span><br><span class="line">        train_num, test_num))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    net = AlexNet(num_classes=5, init_weights=True)</span><br><span class="line"></span><br><span class="line">    net.to(device)</span><br><span class="line">    loss_function = nn.CrossEntropyLoss()</span><br><span class="line">    # pata = list(net.parameters())  #这行代码是用来查看模型的参数</span><br><span class="line">    optimizer = optim.Adam(net.parameters(), lr=0.0002)</span><br><span class="line"></span><br><span class="line">    epochs = 30</span><br><span class="line">    save_path = r&#x27;D:\华清补习文件\code\每日笔记\model\alexnet_flower_improve.pth&#x27;  # 保存网络的路径</span><br><span class="line">    best_acc = 0.0  # 定义这个参数是为了在后边训练网络中保存准确率最高的那次模型</span><br><span class="line">    train_steps = len(train_loader)</span><br><span class="line"></span><br><span class="line">    for epoch in range(epochs):</span><br><span class="line">        # train</span><br><span class="line">        net.train()  # 训练时使用net.train，验证时使用net.eval</span><br><span class="line">        # 我们希望在训练的过程中进行Dropout，预测验证中不进行Dropout</span><br><span class="line">        running_loss = 0.0</span><br><span class="line">        # time_start = time.perf_counter()  #对训练一个epoch计时</span><br><span class="line">        train_bar = tqdm(train_loader, file=sys.stdout)</span><br><span class="line">        for step, data in enumerate(train_bar):</span><br><span class="line">            images, labels = data  # 把数据集分为图像和对应的标签</span><br><span class="line">            optimizer.zero_grad()  # 更新梯度信息</span><br><span class="line">            outputs = net(images.to(device))  # 进行正向传播</span><br><span class="line">            loss = loss_function(outputs, labels.to(device))  # 计算损失</span><br><span class="line">            loss.backward()  # 反向传播</span><br><span class="line">            optimizer.step()  # 更新参数</span><br><span class="line"></span><br><span class="line">            # print statistics</span><br><span class="line">            running_loss += loss.item()  # loss累加</span><br><span class="line"></span><br><span class="line">            train_bar.desc = &quot;train epoch[&#123;&#125;/&#123;&#125;] loss:&#123;:.3f&#125;&quot;.format(</span><br><span class="line">                epoch + 1, epochs, loss)</span><br><span class="line">        # print(&#x27;%f s&#x27;%(time.perf_counter()-time_start))</span><br><span class="line"></span><br><span class="line">        # validate</span><br><span class="line">        net.eval()</span><br><span class="line">        acc = 0.0  # accumulate accurate number / epoch</span><br><span class="line">        with torch.no_grad():  # 禁止pytorch在验证过程中对参数进行跟踪，验证中不会计算损失梯度</span><br><span class="line">            val_bar = tqdm(test_loader, file=sys.stdout)  # tqdm是为validate_loader创建一个带有进度条的可迭代对象，</span><br><span class="line">            # 并将进度条输出到标准输出（sys.stdout)</span><br><span class="line">            for val_data in val_bar:  # 遍历我们的验证集</span><br><span class="line">                val_images, val_labels = val_data  # 把数据集分为图像和标签部分</span><br><span class="line">                outputs = net(val_images.to(device))  # 将图片指认到设备上，传到网络得到输出</span><br><span class="line">                predict_y = torch.max(outputs, dim=1)[1]  # 求得输出最大值，作为预测结果</span><br><span class="line">                acc += torch.eq(predict_y, val_labels.to(device)).sum().item()</span><br><span class="line"></span><br><span class="line">        val_accurate = acc / test_num  # 验证集的准确率</span><br><span class="line">        print(&#x27;[epoch %d] train_loss: %.3f  val_accuracy: %.3f&#x27; %</span><br><span class="line">              (epoch + 1, running_loss / train_steps, val_accurate))</span><br><span class="line"></span><br><span class="line">        if val_accurate &gt; best_acc:  # 如果验证集准确率大于历史最优准确率</span><br><span class="line">            best_acc = val_accurate</span><br><span class="line">            torch.save(net.state_dict(), save_path)  # 保存当前的权重</span><br><span class="line"></span><br><span class="line">    print(&#x27;Finished Training&#x27;)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">if __name__ == &#x27;__main__&#x27;:</span><br><span class="line">    main()</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>测试模型：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br></pre></td><td class="code"><pre><span class="line">import os</span><br><span class="line">import json</span><br><span class="line">import torch</span><br><span class="line">from PIL import Image</span><br><span class="line">from torchvision import transforms</span><br><span class="line">import matplotlib.pyplot as plt</span><br><span class="line">from model import ImprovedAlexNet as AlexNet</span><br><span class="line">import os</span><br><span class="line"></span><br><span class="line">os.environ[&quot;KMP_DUPLICATE_LIB_OK&quot;] = &quot;TRUE&quot;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def main():</span><br><span class="line">    device = torch.device(&quot;cuda:0&quot; if torch.cuda.is_available() else &quot;cpu&quot;)</span><br><span class="line"></span><br><span class="line">    data_transform = transforms.Compose(  # 依然是对数据先进行预处理</span><br><span class="line">        [transforms.Resize((224, 224)),</span><br><span class="line">         transforms.ToTensor(),</span><br><span class="line">         transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])</span><br><span class="line"></span><br><span class="line">    # load image</span><br><span class="line">    img_path = r&quot;D:\华清补习文件\code\每日笔记\goole.act\flower_photos\daisy\5547758_eea9edfd54_n.jpg&quot;</span><br><span class="line">    assert os.path.exists(img_path), &quot;file: &#x27;&#123;&#125;&#x27; dose not exist.&quot;.format(img_path)</span><br><span class="line">    img = Image.open(img_path)  # 直接使用PIL库载入一张图像</span><br><span class="line"></span><br><span class="line">    plt.imshow(img)  # 简单展示一下这张图片</span><br><span class="line">    # [N, C, H, W]</span><br><span class="line">    img = data_transform(img)  # 对图片进行预处理</span><br><span class="line">    # expand batch dimension</span><br><span class="line">    img = torch.unsqueeze(img, dim=0)  # 扩充一个维度，添加一个batch维度</span><br><span class="line"></span><br><span class="line">    class_indict=&#123;&quot;0&quot;: &quot;daisies&quot;, &quot;1&quot;: &quot;dandelion&quot;, &quot;2&quot;: &quot;roses&quot;, &quot;3&quot;: &quot;sunflowers&quot;, &quot;4&quot;: &quot;tulips&quot;&#125;</span><br><span class="line"></span><br><span class="line">    # create model</span><br><span class="line">    model = AlexNet(num_classes=5).to(device)  # 初始化我们的网络</span><br><span class="line"></span><br><span class="line">    # load model weights</span><br><span class="line">    weights_path = r&quot;D:\华清补习文件\code\每日笔记\model\alexnet_flower_improve.pth&quot;</span><br><span class="line">    assert os.path.exists(weights_path), &quot;file: &#x27;&#123;&#125;&#x27; dose not exist.&quot;.format(weights_path)</span><br><span class="line">    model.load_state_dict(torch.load(weights_path))  # 载入我们的网络模型</span><br><span class="line"></span><br><span class="line">    model.eval()  # 进入eval模式，没有dropout的那个</span><br><span class="line">    with torch.no_grad():  # 不跟踪变量的损失梯度</span><br><span class="line">        # predict class</span><br><span class="line">        output = torch.squeeze(model(img.to(device))).cpu()  # 将数据通过model进行正向传播得到输出</span><br><span class="line">        # squeeze将输出进行压缩，把第一个维度的batch压缩掉了</span><br><span class="line">        predict = torch.softmax(output, dim=0)  # softmax得到概率分布</span><br><span class="line">        predict_cla = torch.argmax(predict).numpy()  # 概率最大处所对应的索引值</span><br><span class="line">        print(predict_cla)</span><br><span class="line">        print(predict)</span><br><span class="line">    print_res = &quot;class: &#123;&#125;   prob: &#123;:.3&#125;&quot;.format(class_indict[str(predict_cla)],</span><br><span class="line">                                              predict[predict_cla].numpy())</span><br><span class="line">    # 打印预测名称，已经对应类别的概率</span><br><span class="line">    plt.title(print_res)</span><br><span class="line">    for i in range(len(predict)):</span><br><span class="line">        print(&quot;class: &#123;:10&#125;   prob: &#123;:.3&#125;&quot;.format(class_indict[str(i)],</span><br><span class="line">                                                  predict[i].numpy()))</span><br><span class="line">    plt.show()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">if __name__ == &#x27;__main__&#x27;:</span><br><span class="line">    main()</span><br></pre></td></tr></table></figure>

<h3 id="1-7其他对于训练的方法"><a href="#1-7其他对于训练的方法" class="headerlink" title="1.7其他对于训练的方法"></a>1.7其他对于训练的方法</h3><h4 id="1-7-1读取数据"><a href="#1-7-1读取数据" class="headerlink" title="1.7.1读取数据"></a>1.7.1读取数据</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">import torch</span><br><span class="line">import torch.nn as nn</span><br><span class="line">from torchvision.datasets import ImageFolder</span><br><span class="line">from torchvision import transforms</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">train_data_set = ImageFolder(root=&#x27;./train&#x27;, transform=transforms.Compose([</span><br><span class="line">    transforms.Resize(256),</span><br><span class="line">    transforms.CenterCrop(224),</span><br><span class="line">    transforms.ToTensor(),</span><br><span class="line">    transforms.Normalize(mean=[0.485, 0.456, 0.406],</span><br><span class="line">                         std=[0.229, 0.224, 0.225])</span><br><span class="line">]))</span><br><span class="line"></span><br><span class="line">dc = train_data_set.class_to_idx</span><br><span class="line"># print(dc)</span><br><span class="line">idx_class = &#123;v: k for k, v in dc.items()&#125;</span><br><span class="line">print(idx_class)</span><br><span class="line"></span><br><span class="line">names = train_data_set.classes</span><br><span class="line">print(names)</span><br></pre></td></tr></table></figure>

<p>还可以使用random_split区分训练集和测试集</p>
<p>from  torchvision import random_split</p>
<p>提取数据集的所有种类</p>
<p>数据集.class_to_idx</p>
<h4 id="1-7-2数据训练可视化"><a href="#1-7-2数据训练可视化" class="headerlink" title="1.7.2数据训练可视化"></a>1.7.2数据训练可视化</h4><p>需要先安装tensorboard</p>
<p>在训练的同时使用SummaryWriter保存训练数据，并可视化到本地网站上</p>
<p>writer.add_scaler(“图像名称”,输出值，批次)</p>
<p>writer.add_image(“图像名称”，图像，批次)</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br></pre></td><td class="code"><pre><span class="line">import os</span><br><span class="line">import sys</span><br><span class="line">import json</span><br><span class="line">import torch</span><br><span class="line">import torch.nn as nn</span><br><span class="line">from torchvision import transforms, datasets, utils</span><br><span class="line">from torch.utils.data import DataLoader,random_split</span><br><span class="line">import matplotlib.pyplot as plt</span><br><span class="line">import numpy as np</span><br><span class="line">import torch.optim as optim</span><br><span class="line">from tqdm import tqdm</span><br><span class="line">from model import GoogLeNet</span><br><span class="line">from torch.utils.tensorboard import SummaryWriter</span><br><span class="line">import  tqdm</span><br><span class="line">from datetime import datetime</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line">def train_save(model,train_num,test_num,train_loader,test_loader,optimizer,loss_fn,save_path=&#x27;tesorboard_model_mob.pth&#x27;,epochs=10):</span><br><span class="line">   # 动态生成日志目录</span><br><span class="line">     </span><br><span class="line">     writer=SummaryWriter()</span><br><span class="line">     if torch.cuda.is_available():</span><br><span class="line">        device=torch.device(&quot;cuda&quot;)</span><br><span class="line">     else:</span><br><span class="line">        device=torch.device(&quot;cpu&quot;)</span><br><span class="line">     model.to(device)</span><br><span class="line">     best_acc=0.0</span><br><span class="line">     for epoch in range(epochs):</span><br><span class="line">         model.train()</span><br><span class="line">         running_loss = 0.0</span><br><span class="line">         train_bar = tqdm.tqdm(train_loader, file=sys.stdout)</span><br><span class="line">         for _,data in enumerate(train_bar):</span><br><span class="line">             fuirt,label=data</span><br><span class="line">             fuirt,labels=fuirt.to(device),label.to(device)</span><br><span class="line">             output=model(fuirt)</span><br><span class="line">            #  logits, aux_logits2, aux_logits1 = model(fuirt)</span><br><span class="line">            #  loss0 = loss_fn(logits, labels.to(device))</span><br><span class="line">            #  loss1 = loss_fn(aux_logits1, labels)</span><br><span class="line">            #  loss2 = loss_fn(aux_logits2, labels)</span><br><span class="line">             optimizer.zero_grad()</span><br><span class="line">            #  loss_ = loss0 + loss1 * 0.3 + loss2 * 0.3</span><br><span class="line">             loss_= loss_fn(output, labels)</span><br><span class="line">             loss_.backward()</span><br><span class="line">             optimizer.step()</span><br><span class="line">             running_loss += loss_.item()  # loss累加</span><br><span class="line"></span><br><span class="line">             train_bar.desc = &quot;train epoch[&#123;&#125;/&#123;&#125;] loss:&#123;:.3f&#125;&quot;.format(</span><br><span class="line">                epoch + 1, epochs, loss_)</span><br><span class="line">         if epoch%100==0:</span><br><span class="line">            writer.add_images(f&#x27;rm_&#123;epoch&#125;&#x27;, fuirt, epoch)</span><br><span class="line">         model.eval()</span><br><span class="line">         acc = 0.0  # accumulate accurate number / epoch</span><br><span class="line">         with torch.no_grad():  # 禁止pytorch在验证过程中对参数进行跟踪，验证中不会计算损失梯度</span><br><span class="line">            val_bar = tqdm.tqdm(test_loader, file=sys.stdout)  # tqdm是为validate_loader创建一个带有进度条的可迭代对象，</span><br><span class="line">        # 并将进度条输出到标准输出（sys.stdout)</span><br><span class="line">            for val_data in val_bar:  # 遍历我们的验证集</span><br><span class="line">                val_images, val_labels = val_data  # 把数据集分为图像和标签部分</span><br><span class="line">                outputs = model(val_images.to(device))  # 将图片指认到设备上，传到网络得到输出</span><br><span class="line">                predict_y = torch.max(outputs, dim=1)[1]  # 求得输出最大值，作为预测结果</span><br><span class="line">                acc += torch.eq(predict_y, val_labels.to(device)).sum().item()</span><br><span class="line">         print(acc)</span><br><span class="line">         print(test_num)</span><br><span class="line">         val_accurate = acc / test_num  # 验证集的准确率</span><br><span class="line">         print(&#x27;[epoch %d] train_loss: %.3f  val_accuracy: %.3f&#x27; %</span><br><span class="line">            (epoch + 1, running_loss / train_num, val_accurate))</span><br><span class="line">         writer.add_scalar(&#x27;train_loss&#x27;, running_loss / train_num, epoch)</span><br><span class="line">         writer.add_scalar(&#x27;train_acc&#x27;, acc / train_num, epoch)</span><br><span class="line"></span><br><span class="line">         if val_accurate &gt; best_acc:  # 如果验证集准确率大于历史最优准确率</span><br><span class="line">            best_acc = val_accurate</span><br><span class="line">            torch.save(model.state_dict(), save_path)</span><br><span class="line">         writer.c</span><br></pre></td></tr></table></figure>

<h4 id="1-7-3onnx"><a href="#1-7-3onnx" class="headerlink" title="1.7.3onnx"></a>1.7.3onnx</h4><p>Open Neural Network Exchange（ONNX，开放神经网络交换）格式，是一个用于表示深度学习 模型的标准，可使模型在不同框架之间进行转移。 ONNX的规范及代码主要由微软，亚马逊 ，Face book 和 IBM等公司共同开发，以开放源代码的方 式托管在Github上。目前官方支持加载ONNX模型并进行推理的深度学习框架有： Caffe2, PyTorch, PaddlePaddle， TensorFlow等。</p>
<h5 id="1-7-3-1导出onnx模型"><a href="#1-7-3-1导出onnx模型" class="headerlink" title="1.7.3.1导出onnx模型"></a>1.7.3.1导出onnx模型</h5><p>代码示例</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line">import os</span><br><span class="line">import torch</span><br><span class="line">import torch.nn as nn</span><br><span class="line">from torchvision.models import resnet18</span><br><span class="line">from model_mob import model_mob</span><br><span class="line">if __name__ == &quot;__main__&quot;:</span><br><span class="line">    dir = os.path.dirname(__file__)</span><br><span class="line">    weightpath = os.path.join(</span><br><span class="line">        os.path.dirname(__file__), &quot;pth&quot;, &quot;model_mob_weight.pth&quot;</span><br><span class="line">    )</span><br><span class="line">    onnxpath = os.path.join(</span><br><span class="line">        os.path.dirname(__file__), &quot;pth&quot;, &quot;model_mob_orginal_weight.onnx&quot;</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    device = torch.device(&quot;cuda&quot; if torch.cuda.is_available() else &quot;cpu&quot;)</span><br><span class="line">    # 修改分类器层以适应你的数据集</span><br><span class="line">    num_classes = 10</span><br><span class="line">    model_mob.classifier[3] = torch.nn.Linear(model_mob.classifier[3].in_features, num_classes)</span><br><span class="line">    # 加载你的模型权重</span><br><span class="line">    state_dict = torch.load(r&#x27;D:\python_cnn_project\furit_classif\model_mob.pth&#x27;, map_location=torch.device(&#x27;cpu&#x27;))</span><br><span class="line">    # 从state_dict中移除分类器层的权重</span><br><span class="line">    state_dict.pop(&#x27;classifier.3.weight&#x27;, None)</span><br><span class="line">    state_dict.pop(&#x27;classifier.3.bias&#x27;, None)</span><br><span class="line">    # 加载权重，忽略不匹配的权重</span><br><span class="line">    model_mob.load_state_dict(state_dict, strict=False)#strict: False意思是忽略不匹配的权重</span><br><span class="line">    x=torch.randn(1, 3, 224, 224)</span><br><span class="line">    # 导出onnx</span><br><span class="line">    torch.onnx.export(</span><br><span class="line">        model_mob,</span><br><span class="line">        x,</span><br><span class="line">        onnxpath,</span><br><span class="line">        # verbose=True,  # 输出转换过程</span><br><span class="line">        input_names=[&quot;input&quot;],</span><br><span class="line">        output_names=[&quot;output&quot;],</span><br><span class="line">    )</span><br><span class="line">    print(&quot;onnx导出成功&quot;)</span><br></pre></td></tr></table></figure>

<p>torch.onnx.export(</p>
<p>​    模型,</p>
<p>​    初始化x,</p>
<p>​    导出的地址,</p>
<p>​    # verbose&#x3D;True,  # 输出转换过程</p>
<p>​    input_names&#x3D;[“input”],#输入名</p>
<p>​    output_names&#x3D;[“output”],#输出名</p>
<p>  )</p>
<h5 id="1-7-3-2使用模型"><a href="#1-7-3-2使用模型" class="headerlink" title="1.7.3.2使用模型"></a>1.7.3.2使用模型</h5><p>示例</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br></pre></td><td class="code"><pre><span class="line">import onnxruntime as ort</span><br><span class="line">import torchvision.transforms as transforms</span><br><span class="line">import cv2 as cv</span><br><span class="line">import os</span><br><span class="line">import numpy as np</span><br><span class="line"></span><br><span class="line">img_size = 224</span><br><span class="line">transformtest = transforms.Compose(</span><br><span class="line">    [</span><br><span class="line">        transforms.ToPILImage(),  # 将numpy数组转换为PIL图像</span><br><span class="line">        transforms.Resize((img_size, img_size)),</span><br><span class="line">        transforms.ToTensor(),</span><br><span class="line">        transforms.Normalize(</span><br><span class="line">            # 均值和标准差</span><br><span class="line">            mean=[0.4914, 0.4822, 0.4465],</span><br><span class="line">            std=[0.2471, 0.2435, 0.2615],</span><br><span class="line">        ),</span><br><span class="line">    ]</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">def softmax(x):</span><br><span class="line">    L = np.max(x)</span><br><span class="line">    x = np.exp(x - L)</span><br><span class="line">    return x / np.sum(x, axis=1, keepdims=True)</span><br><span class="line"></span><br><span class="line">def cv_imread(file_path):</span><br><span class="line">    coding = cv.IMREAD_COLOR  # 从文件中读取图像(默认是BGR)</span><br><span class="line">    cv_image = cv.imread(file_path)</span><br><span class="line">    return cv_image</span><br><span class="line"></span><br><span class="line">def test_onnx(img_path,onnx_path,label_name):</span><br><span class="line">    img = cv_imread(img_path)</span><br><span class="line">    img = cv.cvtColor(img, cv.COLOR_BGR2RGB)</span><br><span class="line">    img_tensor = transformtest(img)</span><br><span class="line"></span><br><span class="line">    # 将图片转换为ONNX模型所需的格式</span><br><span class="line">    img_numpy = img_tensor.numpy()</span><br><span class="line">    img_numpy = np.expand_dims(img_numpy, axis=0)  # 增加batch_size维度</span><br><span class="line">    # 加载onnx模型</span><br><span class="line">    sess = ort.InferenceSession(onnx_path)</span><br><span class="line"></span><br><span class="line">    # 运行onnx模型</span><br><span class="line">    outputs = sess.run(None, &#123;&quot;input&quot;: img_numpy&#125;)</span><br><span class="line">    output = outputs[0]</span><br><span class="line"></span><br><span class="line">    # 应用softmax</span><br><span class="line">    probabilities = softmax(output)</span><br><span class="line">    print(probabilities)</span><br><span class="line">    # 获取预测结果</span><br><span class="line">    pred_index = np.argmax(probabilities, axis=1)</span><br><span class="line">    pred_value = probabilities[0][pred_index[0]]</span><br><span class="line">    print(pred_index)</span><br><span class="line"></span><br><span class="line">    print(</span><br><span class="line">        &quot;预测类别：&quot;,</span><br><span class="line">        label_name[pred_index[0]],</span><br><span class="line">        &quot;预测概率：&quot;,</span><br><span class="line">        str(pred_value * 100)[:5] + &quot;%&quot;,</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">if __name__ == &quot;__main__&quot;:</span><br><span class="line">    Fruit_mapping = &#123;</span><br><span class="line">        -1: &#x27;None&#x27;,</span><br><span class="line">        0: &#x27;Carrot&#x27;,</span><br><span class="line">        1: &#x27;Cherry&#x27;,</span><br><span class="line">        2: &#x27;kumquat&#x27;,</span><br><span class="line">        3: &#x27;papa Citrus&#x27;,</span><br><span class="line">        4: &#x27;Pineberry&#x27;,</span><br><span class="line">        5: &#x27;Red Apple&#x27;,</span><br><span class="line">        6: &#x27;Red Dragon Fruit&#x27;,</span><br><span class="line">        7: &#x27;strawberry&#x27;,</span><br><span class="line">        8: &#x27;White Dragon Fruit&#x27;,</span><br><span class="line">        9: &#x27;yellow Peach&#x27;</span><br><span class="line">    &#125;</span><br><span class="line">    dir = os.path.dirname(__file__)</span><br><span class="line">    onnxpath = r&quot;D:\python_cnn_project\furit_classif\pth\model_mob_orginal_weight.onnx&quot;</span><br><span class="line">    # 读取图片</span><br><span class="line">    img_path = r&#x27;D:\python_cnn_project\furit_classif\test\cherry.jpg&#x27;</span><br><span class="line">    test_onnx(img_path, onnxpath, Fruit_mapping)</span><br></pre></td></tr></table></figure>

<p>主要代码</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"># 加载onnx模型</span><br><span class="line">   sess = ort.InferenceSession(onnx_path)</span><br><span class="line"></span><br><span class="line">   # 运行onnx模型</span><br><span class="line">   outputs = sess.run(None, &#123;&quot;input&quot;: img_numpy&#125;)</span><br></pre></td></tr></table></figure>


        </div>

        
            <section class="post-copyright">
                
                    <p class="copyright-item">
                        <span>Author:</span>
                        <span>CXZ</span>
                    </p>
                
                
                    <p class="copyright-item">
                        <span>Permalink:</span>
                        <span><a href="https://cxz-deman.github.io/2025/07/21/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/">https://cxz-deman.github.io/2025/07/21/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/</a></span>
                    </p>
                
                
                    <p class="copyright-item">
                        <span>License:</span>
                        <span>Copyright (c) 2019 <a target="_blank" rel="noopener" href="http://creativecommons.org/licenses/by-nc/4.0/">CC-BY-NC-4.0</a> LICENSE</span>
                    </p>
                
                
                     <p class="copyright-item">
                         <span>Slogan:</span>
                         <span>Do you believe in <strong>god</strong>?</span>
                     </p>
                

            </section>
        
        <section class="post-tags">
            <div>
                <span>Tag(s):</span>
                <span class="tag">
                    
                    
                        <a href="/tags/%E9%98%B6%E6%AE%B5%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E5%90%88%E9%9B%86/"># 阶段学习笔记合集</a>
                    
                        
                </span>
            </div>
            <div>
                <a href="javascript:window.history.back();">back</a>
                <span>· </span>
                <a href="/">home</a>
            </div>
        </section>
        <section class="post-nav">
            
                <a class="prev" rel="prev" href="/2025/07/30/YOLO%E7%AE%97%E6%B3%95/">YOLO算法</a>
            
            
            <a class="next" rel="next" href="/2025/05/06/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">深度学习</a>
            
        </section>


    </article>
</div>

            </div>
            <footer id="footer" class="footer">
    <div class="copyright">
        <span>© CXZ | Powered by <a href="https://hexo.io" target="_blank">Hexo</a> & <a href="https://github.com/Siricee/hexo-theme-Chic" target="_blank">Chic</a></span>
    </div>
</footer>

    </div>
</body>

</html>